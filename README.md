# ğŸ“š Smart Summarizer (LLM + LoRA + LangGraph)

A smart academic summarization system that fine-tunes Large Language Models (LLMs) using **LoRA** and automates literature review through **LangGraph**-based multi-agent orchestration.

---

## ğŸš€ Features

- ğŸ” Summarizes research papers from the **arXiv dataset** using LoRA-tuned **LLaMA/Mistral** models  
- ğŸ¤– Includes a multi-agent system using **LangGraph**:  
  - `KeywordAgent`  
  - `SearchAgent`  
  - `RankAgent`  
  - `SummaryAgent`  
  - `CompareAgent`  
- âš–ï¸ Evaluated with **ROUGE, BLEU, BERTScore**, and LLM-as-a-Judge (fluency, factuality, coverage)  
- ğŸ§ª Compare summaries from base and fine-tuned models  
- ğŸ§  Upload paper + auto-score via **Together.ai API**  
- ğŸ“Š Interactive frontend via **Streamlit/Gradio**  

---

## ğŸ”§ How It Works

1. **Data Preprocessing** â†’ Extracts articles and abstracts from **arXiv** dataset  
2. **LoRA Fine-Tuning** â†’ Uses Hugging Face PEFT to fine-tune attention layers  
3. **Summary Generation** â†’ Generates summaries from base and tuned models  
4. **Evaluation** â†’ Quantitative and qualitative evaluation with LLM-as-a-Judge  
5. **Multi-Agent System** â†’ Uses **LangGraph agents** to simulate automated literature review  
6. **Web App** â†’ Upload a paper, generate and compare summaries, auto-score  

---

## ğŸ“Š Results

### ğŸ“ˆ Quantitative Evaluation (10 samples)

| Metric         | Fine-Tuned Model | Base Model |
|----------------|------------------|------------|
| ROUGE-1        | 0.2732           | 0.2744     |
| ROUGE-L        | 0.1403           | 0.1417     |
| BLEU           | 0.0264           | 0.0264     |
| BERTScore (F1) | 0.8303           | 0.8303     |

âš ï¸ **Note:** Both models returned nearly identical outputs due to a generation issue. Improvements are expected after fixing LoRA inference or decoding parameters.

---

### ğŸ§‘â€âš–ï¸ Qualitative Evaluation (LLM-as-a-Judge, 10 samples, DeepSeek-V3 via Together.ai)

| Criterion   | Avg. Score (out of 5) | Observations |
|-------------|------------------------|--------------|
| Fluency     | 3.9 | Mostly accurate with minor hallucinations |
| Coverage    | 3.6 | Good topical breadth, but often missed fine points |
| Readability | 3.1 | Some summaries well-structured, others awkward |
| Factuality  | 3.6 | Some samples demonstrated excellent accuracy; others showed repetition or placeholders |

---

## ğŸ¨ Visual Evaluation

- Gradio dashboard was used to visualize **ROUGE/ BLEU/ BERTScore** comparisons.  
- Interactive interface allows uploading academic PDFs and scoring summaries via **Together.ai**.  

---

## ğŸ›  Tech Stack

- ğŸ¦™ **LLaMA 3 / Mistral 7B**  
- ğŸŒ¿ **LoRA (PEFT)**  
- ğŸ”— **LangGraph & LangChain**  
- â˜ï¸ **Together.ai API**  
- ğŸ Python, Hugging Face, Streamlit  

---

## ğŸ“¥ Installation

```bash
git clone https://github.com/Farjadkareem/smart-summarizer-LLM-LoRA
cd smart-summarizer
pip install -r requirements.txt

---
## ğŸ“Œ Future Improvements

âœ… Add RAG for improved contextual summaries

âœ… Add PDF/Docx input pipeline

âœ… Enable exportable structured research reports

âœ… Add user feedback loop for continual tuning

---
## ğŸ‘ Acknowledgements

Hugging Face

LoRA PEFT

LangGraph

Together.ai

---
## ğŸ“œ License

MIT License Â© Farjad Kareem
