# ğŸ“š Smart Summarizer (LLM + LoRA + LangGraph)

A smart academic summarization system that fine-tunes Large Language Models (LLMs) using LoRA and automates literature review through LangGraph-based multi-agent orchestration.

---

## ğŸš€ Features

- ğŸ” Summarizes research papers from the arXiv dataset using LoRA-tuned LLaMA/Mistral models
- ğŸ¤– Includes a multi-agent system using LangGraph (KeywordAgent, SearchAgent, RankAgent, SummaryAgent, CompareAgent)
- âš–ï¸ Evaluated with ROUGE, BLEU, BERTScore, and LLM-as-a-Judge (fluency, factuality, coverage)
- ğŸ§ª Compare summaries from base and fine-tuned models
- ğŸ§  Upload paper + auto score via Together.ai API
- ğŸ“Š Interactive frontend via Streamlit/Gradio

---

---

## ğŸ§  How It Works

1. **Data Preprocessing:** Extracts articles and abstracts from arXiv dataset  
2. **LoRA Fine-Tuning:** Uses Hugging Face PEFT to fine-tune attention layers  
3. **Summary Generation:** Generates summaries from base and tuned models  
4. **Evaluation:** Quantitative and qualitative evaluation with LLM-as-a-Judge  
5. **Multi-Agent System:** Uses LangGraph agents to simulate automated literature review  
6. **Web App:** Upload a paper, generate and compare summaries, auto score

---

## ğŸ“Š Results

### ğŸ”¢ Quantitative Evaluation (10 test samples)

| Metric        | Fine-Tuned Model | Base Model  |
|---------------|------------------|-------------|
| ROUGE-1       | 0.2732           | 0.2744      |
| ROUGE-L       | 0.1403           | 0.1417      |
| BLEU          | 0.0251           | 0.0264      |
| BERTScore (F1)| 0.8303           | 0.8303      |

> âš ï¸ Note: Both models returned nearly identical outputs due to a generation issue. Improvements are expected after fixing LoRA inference or decoding parameters.

---

### ğŸ¤– Qualitative Evaluation (LLM-as-a-Judge)

Assessed on 10 summaries using DeepSeek-V3 (via Together.ai) with the following average ratings:

| Criterion   | Average Score (out of 5) | Observations                                       |
|-------------|---------------------------|----------------------------------------------------|
| Fluency     | 3.1                       | Some summaries well-structured, others awkward     |
| Factuality  | 3.9                       | Mostly accurate with minor hallucinations          |
| Coverage    | 3.6                       | Good topical breadth, but often missed fine points |

> Some samples demonstrated excellent readability and accuracy, while others suffered from repetition or placeholder artifacts.

---

### ğŸ§ª Visual Evaluation

- Gradio dashboard was used to visualize ROUGE/BLEU/BERTScore comparisons  
- Interactive interface allows uploading academic PDFs and scoring summaries via Together.ai  

---

## âš™ï¸ Tech Stack

- ğŸ§  LLaMA 3 / Mistral 7B
- ğŸ§© LoRA (PEFT)
- ğŸ§ª LangGraph & LangChain
- ğŸ”— Together.ai API
- ğŸ Python, Hugging Face, Streamlit

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/yourusername/smart-summarizer
cd smart-summarizer
pip install -r requirements.txt
```

---

## ğŸ“Œ Future Improvements

- âœ… Add RAG for improved contextual summaries  
- âœ… Add PDF/Docx input pipeline  
- âœ… Enable exportable structured research reports  
- âœ… Add user feedback loop for continual tuning

---

## ğŸ™Œ Acknowledgements

- [Hugging Face](https://huggingface.co/)
- [LoRA PEFT](https://github.com/huggingface/peft)
- [LangGraph](https://github.com/langchain-ai/langgraph)
- [Together.ai](https://www.together.ai/)

---

## ğŸ“„ License

MIT License Â© Farjad Kareem
