{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd1c6159-1cd6-4f3d-afbf-9a6b8877e543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f8b9d1e-4e7a-4b44-9308-33c200793243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ffb1d9f-b1c6-4529-8529-a5d37b3f2705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f6b036-ada6-4cf4-9a25-3f581d4421ee",
   "metadata": {},
   "source": [
    "# Part 1: Data Preprocessing\n",
    "● Load the arXiv summarization dataset.\n",
    "● Select a subset of 5,000 samples.\n",
    "● Extract input and target pairs:\n",
    "○ Input: Article.\n",
    "○ Target: Abstract/Summary\n",
    "● Tokenize the dataset using the tokenizer from your base model.\n",
    "● Split the data into Training (80%), Validation (10%), and Test (10%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6b34fb2-e41f-4496-acc0-8c64c686def0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ccdv/arxiv-summarization\")\n",
    "subset = dataset['train'].select(range(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d87e2b0-5b9b-4ed2-a6fd-05ca9d5cb8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    return {\n",
    "        \"input\": example[\"article\"],\n",
    "        \"target\": example[\"abstract\"]\n",
    "    }\n",
    "subset = subset.map(preprocess, remove_columns=subset.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b917915-89d0-43b8-b6aa-dcfe0adb897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_path = \"./Llama-3.2-3B-Instruct\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "526e1b40-64db-4fb8-99cd-e2130f9b9133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    model_inputs = tokenizer(\n",
    "        example[\"input\"], max_length=512, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        example[\"target\"], max_length=512, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = subset.map(tokenize_function, batched=True, remove_columns=[\"input\", \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db050c26-155d-49af-bd0f-2746d2e4403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 4000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "indices = list(range(len(tokenized_dataset)))\n",
    "train_val_indices, test_indices = train_test_split(indices, test_size=0.1, random_state=42)\n",
    "train_indices, val_indices = train_test_split(train_val_indices, test_size=0.1111, random_state=42)  # 0.1111*0.9 ≈ 0.1\n",
    "\n",
    "train = tokenized_dataset.select(train_indices)\n",
    "val = tokenized_dataset.select(val_indices)\n",
    "test = tokenized_dataset.select(test_indices)\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train,\n",
    "    \"validation\": val,\n",
    "    \"test\": test\n",
    "})\n",
    "\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a7972a-4398-464a-8c58-db49b94278bb",
   "metadata": {},
   "source": [
    "# Part 2: LoRA-Based Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35feea04-9bfa-4f08-9bdd-2e6ea28a1eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in c:\\users\\farjad\\anaconda3\\envs\\jupyter-gpu\\lib\\site-packages (0.45.5)\n",
      "Requirement already satisfied: torch<3,>=2.0 in c:\\users\\farjad\\anaconda3\\envs\\jupyter-gpu\\lib\\site-packages (from bitsandbytes) (2.5.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\farjad\\anaconda3\\envs\\jupyter-gpu\\lib\\site-packages (from bitsandbytes) (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\farjad\\anaconda3\\envs\\jupyter-gpu\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\farjad\\anaconda3\\envs\\jupyter-gpu\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\farjad\\anaconda3\\envs\\jupyter-gpu\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\farjad\\anaconda3\\envs\\jupyter-gpu\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\farjad\\anaconda3\\envs\\jupyter-gpu\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\farjad\\anaconda3\\envs\\jupyter-gpu\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\farjad\\anaconda3\\envs\\jupyter-gpu\\lib\\site-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\farjad\\anaconda3\\envs\\jupyter-gpu\\lib\\site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4d0acb9-3e12-4f12-a74d-9a14b402359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from peft import LoraConfig, get_peft_model, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "592e1944-f35c-4583-b788-0237cc952bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [00:12<00:00,  6.21s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    local_model_path,\n",
    "    torch_dtype=torch.float16  # or \"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbb9a764-e959-4671-8bc4-2ba33cd7f838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,293,760 || all params: 3,215,043,584 || trainable%: 0.0713\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d87f8dfb-b70b-4795-b15e-aeb876755f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False\n",
    ")\n",
    "\n",
    "# 4. Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora-llama3-3b-arxiv\",\n",
    "    per_device_train_batch_size=2,  # Try 2, increase if you have spare VRAM\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=4,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    fp16=True,\n",
    "    learning_rate=2e-4,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abda5db2-ae11-4c2d-ac5f-32450d020f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_dict[\"train\"],\n",
    "    eval_dataset=dataset_dict[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4561bf14-cd0c-48eb-b169-dc03af426d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 3:23:01, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.238100</td>\n",
       "      <td>2.243297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.208800</td>\n",
       "      <td>2.224691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.156300</td>\n",
       "      <td>2.218255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.154300</td>\n",
       "      <td>2.216240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./lora-llama3-3b-arxiv/final\\\\tokenizer_config.json',\n",
       " './lora-llama3-3b-arxiv/final\\\\special_tokens_map.json',\n",
       " './lora-llama3-3b-arxiv/final\\\\tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "# 7. Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"./lora-llama3-3b-arxiv/final\")\n",
    "tokenizer.save_pretrained(\"./lora-llama3-3b-arxiv/final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "586ac530-2e9f-4363-a8e6-b95ab96da462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d2542e2-1c2f-4023-9848-5ac160cfa5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model_path = \"./lora-llama3-3b-arxiv/final\"\n",
    "base_model_path = \"./Llama-3.2-3B-Instruct\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b912a432-e1d3-4b31-b5da-1602ce6624fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-bit quantization config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5879151-c02c-466d-86cc-decba9b58ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.25s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load fine-tuned model and tokenizer in 4-bit on GPU\n",
    "finetuned_tokenizer = AutoTokenizer.from_pretrained(finetuned_model_path, use_fast=True)\n",
    "if finetuned_tokenizer.pad_token is None:\n",
    "    finetuned_tokenizer.pad_token = finetuned_tokenizer.eos_token\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(\n",
    "    finetuned_model_path,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "068a79df-08d4-4f03-a7e1-443ce24f2d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.09s/it]\n"
     ]
    }
   ],
   "source": [
    "base_tokenizer = AutoTokenizer.from_pretrained(base_model_path, use_fast=True)\n",
    "if base_tokenizer.pad_token is None:\n",
    "    base_tokenizer.pad_token = base_tokenizer.eos_token\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8617b421-0240-4815-b622-b985940041f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = dataset_dict[\"test\"].select(range(10))\n",
    "inputs = subset.select(test_indices)[:10][\"input\"]\n",
    "ground_truths = subset.select(test_indices)[:10][\"target\"]\n",
    "\n",
    "def generate_summaries(inputs, model, tokenizer):\n",
    "    summaries = []\n",
    "    for text in inputs:\n",
    "        inputs_enc = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=\"max_length\")\n",
    "        input_ids = inputs_enc.input_ids.to(device)\n",
    "        attention_mask = inputs_enc.attention_mask.to(device)\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_new_tokens=128,  # or 256 if you want longer summaries\n",
    "                num_beams=4,\n",
    "                do_sample=False\n",
    "            )\n",
    "        summary = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        summaries.append(summary)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcc5b198-a44e-48b6-90c9-f94040df4f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Farjad\\anaconda3\\envs\\jupyter-gpu\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Farjad\\anaconda3\\envs\\jupyter-gpu\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "finetuned_summaries = generate_summaries(inputs, finetuned_model, finetuned_tokenizer)\n",
    "base_summaries = generate_summaries(inputs, base_model, base_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7a53c5f-ce0e-4dc3-9bf6-87ed032bf5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summaries_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"input\": inputs,\n",
    "    \"ground_truth\": ground_truths,\n",
    "    \"finetuned_summary\": finetuned_summaries,\n",
    "    \"base_summary\": base_summaries\n",
    "})\n",
    "df.to_csv(\"summaries_comparison.csv\", index=False)\n",
    "print(\"Saved summaries_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7291d9d1-1d85-4b78-a7be-3d69f84ac715",
   "metadata": {},
   "source": [
    "# Part 4: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22cc6cd9-d0b1-4062-8c7d-83d794e69dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import evaluate\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from bert_score import score as bert_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d4cff05-93e5-4be9-bdce-fe8d40c91f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               input  \\\n",
      "0  the family of iron oxyarsenide @xmath5feaso@xm...   \n",
      "1  we present here l and m band results on v4332 ...   \n",
      "2  understanding the processes involved in the su...   \n",
      "3  non - relativistic quantum fluids ( fermions o...   \n",
      "4  the recent measurements of the vector charmoni...   \n",
      "5  at a continuous transition , the expression @x...   \n",
      "6  experimental studies of neutrino oscillations ...   \n",
      "7  in this paper , we present a formal analysis o...   \n",
      "8  a major goal of neutron star ( ns ) research h...   \n",
      "9  studies of lateral interactions between adsorb...   \n",
      "\n",
      "                                        ground_truth  \\\n",
      "0  the iron arsenide rbfe@xmath0as@xmath0 with th...   \n",
      "1  l and m band observations of the nova - like v...   \n",
      "2  we investigate the structure of hybrid stars b...   \n",
      "3  we report the thermodynamic properties of bose...   \n",
      "4  we show that the newly measured branching rati...   \n",
      "5  a simple systematic rule , inspired by high - ...   \n",
      "6  we study the generation of small neutrino mass...   \n",
      "7  an analysis of electromagnetic corrections to ...   \n",
      "8  recently @xcite reported the first clear detec...   \n",
      "9  we present monte carlo simulations using an eq...   \n",
      "\n",
      "                                   finetuned_summary  \\\n",
      "0  the family of iron oxyarsenide @xmath5feaso@xm...   \n",
      "1  we present here l and m band results on v4332 ...   \n",
      "2  understanding the processes involved in the su...   \n",
      "3  non - relativistic quantum fluids ( fermions o...   \n",
      "4  the recent measurements of the vector charmoni...   \n",
      "5  at a continuous transition, the expression @xm...   \n",
      "6  experimental studies of neutrino oscillations ...   \n",
      "7  in this paper, we present a formal analysis of...   \n",
      "8  a major goal of neutron star ( ns ) research h...   \n",
      "9  studies of lateral interactions between adsorb...   \n",
      "\n",
      "                                        base_summary  \n",
      "0  the family of iron oxyarsenide @xmath5feaso@xm...  \n",
      "1  we present here l and m band results on v4332 ...  \n",
      "2  understanding the processes involved in the su...  \n",
      "3  non - relativistic quantum fluids ( fermions o...  \n",
      "4  the recent measurements of the vector charmoni...  \n",
      "5  at a continuous transition, the expression @xm...  \n",
      "6  experimental studies of neutrino oscillations ...  \n",
      "7  in this paper, we present a formal analysis of...  \n",
      "8  a major goal of neutron star ( ns ) research h...  \n",
      "9  studies of lateral interactions between adsorb...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"summaries_comparison.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5175664-3842-41aa-839b-2fc54a5882c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "rouge_finetuned = rouge.compute(predictions=df[\"finetuned_summary\"], references=df[\"ground_truth\"])\n",
    "rouge_base = rouge.compute(predictions=df[\"base_summary\"], references=df[\"ground_truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ae6b2ad-8160-4848-bf46-0f3a42c7ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLEU\n",
    "smooth = SmoothingFunction().method1\n",
    "bleu_finetuned = [sentence_bleu([ref.split()], pred.split(), smoothing_function=smooth) for ref, pred in zip(df[\"ground_truth\"], df[\"finetuned_summary\"])]\n",
    "bleu_base = [sentence_bleu([ref.split()], pred.split(), smoothing_function=smooth) for ref, pred in zip(df[\"ground_truth\"], df[\"base_summary\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "760c6b42-8bbc-4cbe-963e-5a96404df5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BERTScore\n",
    "P_finetuned, R_finetuned, F1_finetuned = bert_score(df[\"finetuned_summary\"].tolist(), df[\"ground_truth\"].tolist(), lang=\"en\")\n",
    "P_base, R_base, F1_base = bert_score(df[\"base_summary\"].tolist(), df[\"ground_truth\"].tolist(), lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a0b770d-2710-421d-867c-01f5a1fa98d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate results\n",
    "results = {\n",
    "    \"ROUGE-1\": [rouge_finetuned[\"rouge1\"], rouge_base[\"rouge1\"]],\n",
    "    \"ROUGE-L\": [rouge_finetuned[\"rougeL\"], rouge_base[\"rougeL\"]],\n",
    "    \"BLEU\": [sum(bleu_finetuned)/len(bleu_finetuned), sum(bleu_base)/len(bleu_base)],\n",
    "    \"BERTScore\": [F1_finetuned.mean().item(), F1_base.mean().item()]\n",
    "}\n",
    "labels = [\"Fine-tuned\", \"Base\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36a48af1-5514-4aea-812e-7d3426d27545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXmlJREFUeJzt3Xl8TPf+x/F39sheIgtCEAS1NamUVlFp7VvttMhF2x+qBC1dBG2lFOW2tlLLrdtKra2d5lLrpaVutbXvV0UoEkITkvP7wyNzjSQk4WSI1/PxOA/me77nnM+ZmWTynu9Z7AzDMAQAAAAAAO47e1sXAAAAAABAYUXoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGgIeEnZ2dRo4caZNtb9y4UXZ2dtq4caNNtv8gatCggRo0aGDrMu7Klu+bh8nx48dlZ2enuXPn2roU5MG9/G6aO3eu7OzsdPz48fteFwDcitANAHmQ+UdaTtO///1vW5d4T6ZOnfrAhY4GDRrIzs5OFSpUyHb++vXrLc//okWL8rz+P/74QyNHjtSePXvusdKClxk4sps6d+5s6/IeyPfTgy673zF+fn5q2LChVq9ebevyctSzZ0/Z2dnJy8tL165dyzL/0KFDlv0ZP368DSoEANtxtHUBAPAwGj16tMqWLZulPSQkxAbV3D9Tp06Vr6+vevbsadX+7LPP6tq1a3J2drZJXa6urjp8+LB27typ2rVrW8375z//KVdXV/3111/5Wvcff/yhUaNGKTg4WDVr1sz1cuvWrcvX9swwYMAAPfnkk1ZtwcHBkqRr167J0dE2H/c5vZ9wd5m/YwzD0NmzZzV37lw1a9ZMy5cvV4sWLWxdXrYcHR119epVLV++XB07drSad68/pwDwMCN0A0A+NG3aVOHh4bYuo8DY29vL1dXVZtsvX768bty4oa+//toqdP/1119aunSpmjdvrsWLFxdILVevXpWbm5vNvoDITr169dS+ffts59nydUP+3f47plevXvL399fXX3/9wIZuFxcXPf300/r666+zhO6vvvqqQH9OAeBBwuHlAHCfXb9+XUWLFlVUVFSWecnJyXJ1ddWQIUMkSWlpaRoxYoTCwsLk7e0td3d31atXTxs2bLjrdnr27GkZzbzVyJEjZWdnZ9U2Z84cPffcc/Lz85OLi4uqVKmiadOmWfUJDg7Wb7/9ph9++MFyGGjmOcs5nTe5cOFChYWFqUiRIvL19dVLL72k06dPZ6nTw8NDp0+fVps2beTh4aHixYtryJAhSk9Pv+t+ZurSpYvi4uKUkZFhaVu+fLmuXr2a5Q/8TKdPn9bf/vY3+fv7y8XFRVWrVtXs2bMt8zdu3GgZIY6KirLsd+Yh0Q0aNNDjjz+uXbt26dlnn5Wbm5vefvtty7zbz+n+66+/NHLkSFWsWFGurq4KDAzUiy++qCNHjlj6LFiwQGFhYfL09JSXl5eqVaumyZMnW63nyJEjVsvci9vP6c58fxw+fFg9e/aUj4+PvL29FRUVpatXr2ZZfv78+ZbXuGjRourcubNOnTp11+3e6f2U3XtUyv4c2+DgYLVo0UJbtmxR7dq15erqqnLlyukf//hHluUvXbqkgQMHKigoSC4uLgoJCdHYsWOt3jOZ/Xr27Clvb2/5+PioR48eunTp0l336aeffpKdnZ3mzZuXZd7atWtlZ2enFStWSJIuX76sgQMHKjg4WC4uLvLz89Pzzz+v3bt333U72fHx8VGRIkWyHLUwfvx41a1bV8WKFVORIkUUFhaW7WkW69ev1zPPPCMfHx95eHioUqVKlvdyptTUVMXExCgkJEQuLi4KCgrSm2++qdTU1FzX2bVrV61evdrq+fzxxx916NAhde3aNdtljh49qg4dOqho0aJyc3PTU089pZUrV2bp99///ldt2rSRu7u7/Pz8NGjQoBxr27Fjh5o0aSJvb2+5ubmpfv362rp1a673AwDuJ0a6ASAfkpKSdP78eas2Ozs7FStWTE5OTmrbtq2WLFmiGTNmWI2ILlu2TKmpqZbzbZOTkzVr1ix16dJFffr00eXLl/XFF1+ocePG2rlzZ54Od76TadOmqWrVqmrVqpUcHR21fPly9e3bVxkZGerXr58kadKkSXr99dfl4eGhd955R5Lk7++f4zrnzp2rqKgoPfnkk4qNjdXZs2c1efJkbd26VT///LN8fHwsfdPT09W4cWNFRERo/Pjx+v777zVhwgSVL19e//d//5erfejatatGjhypjRs36rnnnpN0c/SsUaNG8vPzy9L/7Nmzeuqpp2RnZ6f+/furePHiWr16tXr16qXk5GQNHDhQlStX1ujRozVixAi98sorqlevniSpbt26lvX8+eefatq0qTp37qyXXnopx+ckPT1dLVq0UHx8vDp37qw33nhDly9f1vr16/Xrr7+qfPnyWr9+vbp06aJGjRpp7NixkqR9+/Zp69ateuONNyzratSokSTl+gJPly9fzvJ+LFq0qOztc/5uvWPHjipbtqxiY2O1e/duzZo1S35+fpa6JOnDDz/Ue++9p44dO6p37946d+6cPv30Uz377LNZXuPb5fX9dCeHDx9W+/bt1atXL/Xo0UOzZ89Wz549FRYWpqpVq0q6eQRC/fr1dfr0ab366qsqXbq0tm3bpuHDh+vMmTOaNGmSJMkwDLVu3VpbtmzRa6+9psqVK2vp0qXq0aPHXesIDw9XuXLl9M0332TpHxcXp8cee0yNGzeWJL322mtatGiR+vfvrypVqujPP//Uli1btG/fPj3xxBN33Vbm7xjDMJSYmKhPP/1UV65c0UsvvWTVb/LkyWrVqpW6deumtLQ0LViwQB06dNCKFSvUvHlzSdJvv/2mFi1aqHr16ho9erRcXFx0+PBhqxCakZGhVq1aacuWLXrllVdUuXJl7d27V5988okOHjyoZcuW3bVmSXrxxRf12muvacmSJfrb3/4m6ebPaWhoaLb7ffbsWdWtW1dXr17VgAEDVKxYMc2bN0+tWrXSokWL1LZtW0k3T5No1KiRTp48qQEDBqhEiRL68ssv9a9//SvLOv/1r3+padOmCgsLU0xMjOzt7S1fPG7evDnLKSoAYDoDAJBrc+bMMSRlO7m4uFj6rV271pBkLF++3Gr5Zs2aGeXKlbM8vnHjhpGammrV5+LFi4a/v7/xt7/9zapdkhETE2N53KNHD6NMmTJZaoyJiTFu//V+9erVLP0aN25sVYthGEbVqlWN+vXrZ+m7YcMGQ5KxYcMGwzAMIy0tzfDz8zMef/xx49q1a5Z+K1asMCQZI0aMsKpTkjF69GirddaqVcsICwvLsq3b1a9f36hataphGIYRHh5u9OrVyzCMm8+Ts7OzMW/ePEt9CxcutCzXq1cvIzAw0Dh//rzV+jp37mx4e3tbnpMff/zRkGTMmTMn221LMqZPn57tvFufq9mzZxuSjIkTJ2bpm5GRYRiGYbzxxhuGl5eXcePGjTvuc5kyZbJ9bW+Xud/ZTceOHTMMI+v7JvP9cfv7q23btkaxYsUsj48fP244ODgYH374oVW/vXv3Go6Ojlnas5PT+ym796hh/O/nK7N2w7j5XEgyNm3aZGlLTEw0XFxcjMGDB1va3n//fcPd3d04ePCg1TqHDRtmODg4GCdPnjQMwzCWLVtmSDLGjRtn6XPjxg2jXr16Ob4PbjV8+HDDycnJuHDhgqUtNTXV8PHxsXpOvb29jX79+t1xXdnJ6XeMi4uLMXfu3Cz9b//ZTktLMx5//HHjueees7R98sknhiTj3LlzOW73yy+/NOzt7Y3NmzdbtU+fPt2QZGzduvWOdffo0cNwd3c3DMMw2rdvbzRq1MgwDMNIT083AgICjFGjRhnHjh0zJBkff/yxZbmBAwcakqy2e/nyZaNs2bJGcHCwkZ6ebhiGYUyaNMmQZHzzzTeWfikpKUZISIjV76aMjAyjQoUKRuPGjS0/d5nPU9myZY3nn3/e0pbd+w0AzMDh5QCQD1OmTNH69eutpluvLPzcc8/J19dXcXFxlraLFy9q/fr16tSpk6XNwcHBMhKekZGhCxcu6MaNGwoPD8/3YajZKVKkiOX/mSNo9evX19GjR5WUlJTn9f30009KTExU3759rc4Zbt68uUJDQ7M9NPS1116zelyvXj0dPXo0T9vt2rWrlixZorS0NC1atEgODg6WkbBbGYahxYsXq2XLljIMQ+fPn7dMjRs3VlJSUq6fXxcXl2xPFbjd4sWL5evrq9dffz3LvMxDqX18fJSSkqL169ffcV3Hjx/P022MRowYkeX9GBAQcMdlsns9/vzzTyUnJ0uSlixZooyMDHXs2NHq+QsICFCFChVydQrE/VKlShXLUQiSVLx4cVWqVMnq/bNw4ULVq1dPjz32mFW9kZGRSk9P16ZNmyRJq1atkqOjo9URFg4ODtm+btnp1KmTrl+/riVLllja1q1bp0uXLln9bPv4+GjHjh36448/8rXPt/6OmT9/vho2bKjevXtbbVey/tm+ePGikpKSVK9ePav3d+YRCd9++22WQ+0zLVy4UJUrV1ZoaKjV85d5VEleXu+uXbtq48aNSkhI0L/+9S8lJCTkeGj5qlWrVLt2bT3zzDOWNg8PD73yyis6fvy4fv/9d0u/wMBAq2sXuLm56ZVXXrFa3549eyyHsv/555+W/UhJSVGjRo20adOmHJ8DADALh5cDQD7Url37jhdSc3R0VLt27fTVV18pNTVVLi4uWrJkia5fv271h7kkzZs3TxMmTND+/ft1/fp1S3t2V0fPr61btyomJkbbt2/Pct5uUlKSvL2987S+EydOSJIqVaqUZV5oaKi2bNli1ebq6qrixYtbtT322GO6ePFinrbbuXNnDRkyRKtXr9Y///lPtWjRQp6enln6nTt3TpcuXdLnn3+uzz//PNt1JSYm5mqbJUuWzNVF044cOaJKlSrd8Urhffv21TfffKOmTZuqZMmSeuGFF9SxY0c1adIkV7XkpFq1aoqMjMzTMqVLl7Z6/Nhjj0m6Gdy8vLx06NAhGYaR463anJycJElXrlzRlStXLO0ODg5ZXut7dXutmfXe+v45dOiQfvnllxy3nfl6nzhxQoGBgfLw8LCan917OTs1atRQaGio4uLi1KtXL0k3Dy339fW1BFRJGjdunHr06KGgoCCFhYWpWbNm6t69u8qVK5er7dz+O6ZLly6qVauW+vfvrxYtWljekytWrNAHH3ygPXv2WJ3ffOs58506ddKsWbPUu3dvDRs2TI0aNdKLL76o9u3bW05BOHTokPbt23fX5y83mjVrJk9PT8XFxWnPnj168sknFRISku0XSSdOnFBERESW9sqVK1vmP/744zpx4oRCQkKyXAvg9tft0KFDknTH0wWSkpIs73cAKAiEbgAwSefOnTVjxgytXr1abdq00TfffKPQ0FDVqFHD0mf+/Pnq2bOn2rRpo6FDh8rPz08ODg6KjY2964W0srsQlaQsFyc7cuSIGjVqpNDQUE2cOFFBQUFydnbWqlWr9MknnxTIqI+Dg8N9WU9gYKAaNGigCRMmaOvWrTleCTlzn1566aUc//iuXr16rrZ560jivfLz89OePXu0du1arV69WqtXr9acOXPUvXv3bC/OZaacXhPDMCTdfA7t7Oy0evXqbPtmhtbx48dr1KhRlvYyZcrcdZQ+t+/d3NaaWe/zzz+vN998M9u+FStWvGNNedGpUyd9+OGHOn/+vDw9PfXdd9+pS5cuVl+4dOzYUfXq1dPSpUu1bt06ffzxxxo7dqyWLFmipk2b5nmb9vb2atiwoSZPnqxDhw6patWq2rx5s1q1aqVnn31WU6dOVWBgoJycnDRnzhx99dVXlmWLFCmiTZs2acOGDVq5cqXWrFmjuLg4Pffcc1q3bp0cHByUkZGhatWqaeLEidluPygoKNe1uri46MUXX9S8efN09OhRqwv5mS3zZ//jjz/O8ZoYt3/hAgBmI3QDgEmeffZZBQYGKi4uTs8884z+9a9/WS4olWnRokUqV66clixZYhVEYmJi7rr+xx57LNsrLmeOQmdavny5UlNT9d1331mNGGZ3uGhOYeh2ZcqUkSQdOHDAanQvsy1zvhm6du2q3r17y8fHR82aNcu2T/HixeXp6an09PS7jgDndp/vpnz58tqxY4euX79uGQXOjrOzs1q2bKmWLVsqIyNDffv21YwZM/Tee+89UPd5L1++vAzDUNmyZe8YWLt37251aPCtX1Lk9NxmjjJeunTJ6mJst79381rvlStX7vp6lylTRvHx8bpy5YpV+Dpw4ECut9WpUyeNGjVKixcvlr+/v5KTky0XR7xVYGCg+vbtq759+yoxMVFPPPGEPvzww3yFbkm6ceOGJFmOLFi8eLFcXV21du1aubi4WPrNmTMny7L29vZq1KiRGjVqpIkTJ2rMmDF65513tGHDBkVGRqp8+fL6z3/+o0aNGt2Xn4muXbtq9uzZsre3z/a5yVSmTJlsn/v9+/db5mf+++uvv8owDKv6bl+2fPnykiQvL688H/0BAGbhnG4AMIm9vb3at2+v5cuX68svv9SNGzeyHFqeOYJ364jdjh07tH379ruuv3z58kpKStIvv/xiaTtz5oyWLl16120kJSVl+4e5u7t7rm6dFB4eLj8/P02fPt3qkNbVq1dr3759lqsmm6F9+/aKiYnR1KlTczzs28HBQe3atdPixYv166+/Zpl/7tw5y//d3d0lKVf7fSft2rXT+fPn9dlnn2WZl/nc//nnn1bt9vb2lhH3W5/H+3nLsPx68cUX5eDgoFGjRlm9d6Sb+5O5L+XKlVNkZKRlevrppy39cno/ZQajzPOsJSklJeWeRvs7duyo7du3a+3atVnmXbp0yRJYmzVrphs3bljdMi89PV2ffvpprrdVuXJlVatWTXFxcYqLi1NgYKCeffZZq/Xdfq0EPz8/lShRIk+337rV9evXtW7dOjk7O1sOvXZwcJCdnZ3VEQLHjx/PcqXxCxcuZFlf5ihwZj0dO3bU6dOnNXPmzCx9r127ppSUlDzV27BhQ73//vv67LPP7nh9gWbNmmnnzp1Wv/NSUlL0+eefKzg4WFWqVLH0++OPP6xuh3b16tUsp4+EhYWpfPnyGj9+vNVpD5lu/dkHgILCSDcA5MPq1astIzG3qlu3rtU5m506ddKnn36qmJgYVatWzfLHcqYWLVpoyZIlatu2rZo3b65jx45p+vTpqlKlSrZ/MN6qc+fOeuutt9S2bVsNGDBAV69e1bRp01SxYkWriyi98MILltHVV199VVeuXNHMmTPl5+enM2fOWK0zLCxM06ZN0wcffKCQkBD5+fllGcmWbp7PO3bsWEVFRal+/frq0qWL5ZZhwcHBGjRoUK6ex/zw9vbO1eGqH330kTZs2KCIiAj16dNHVapU0YULF7R79259//33liBSvnx5+fj4aPr06fL09JS7u7siIiLyfE599+7d9Y9//EPR0dHauXOn6tWrp5SUFH3//ffq27evWrdurd69e+vChQt67rnnVKpUKZ04cUKffvqpatasafXeyOstw8xQvnx5ffDBBxo+fLiOHz+uNm3ayNPTU8eOHdPSpUv1yiuvWO43n5Oc3k8vvPCCSpcurV69emno0KFycHDQ7NmzVbx4cZ08eTJf9Q4dOlTfffedWrRoYbmdWEpKivbu3atFixbp+PHj8vX1VcuWLfX0009r2LBhOn78uKpUqaIlS5bk+YKCnTp10ogRI+Tq6qpevXpZ3Z7t8uXLKlWqlNq3b68aNWrIw8ND33//vX788UdNmDAhV+u/9XdMYmKivvrqKx06dEjDhg2Tl5eXpJsXLpw4caKaNGmirl27KjExUVOmTFFISIjVl3GjR4/Wpk2b1Lx5c5UpU0aJiYmaOnWqSpUqZTlK4eWXX9Y333yj1157TRs2bNDTTz+t9PR07d+/X998843Wrl17x+tY3M7e3l7vvvvuXfsNGzZMX3/9tZo2baoBAwaoaNGimjdvno4dO6bFixdbntc+ffros88+U/fu3bVr1y4FBgbqyy+/lJubW5btzpo1S02bNlXVqlUVFRWlkiVL6vTp09qwYYO8vLy0fPnyXO8HANwXtrloOgA8nO50yzBlc7uhjIwMIygoyJBkfPDBB1nWl5GRYYwZM8YoU6aM4eLiYtSqVctYsWJFtrcD0223fjIMw1i3bp3x+OOPG87OzkalSpWM+fPnZ3s7pu+++86oXr264erqagQHBxtjx4613OLq1tvlJCQkGM2bNzc8PT0NSZbbPd1+y7BMcXFxRq1atQwXFxejaNGiRrdu3Yz//ve/Vn1uvZXQrXK6bdTtbr1lWE6yu2WYYRjG2bNnjX79+hlBQUGGk5OTERAQYDRq1Mj4/PPPrfp9++23RpUqVQxHR0er1/FO2779lmGGcfO2RO+8845RtmxZy/bat29vHDlyxDAMw1i0aJHxwgsvGH5+foazs7NRunRp49VXXzXOnDljtZ683jLs9v2+1e3vm8zn/fbbR+V0+6TFixcbzzzzjOHu7m64u7sboaGhRr9+/YwDBw7ctb6c3k+GYRi7du0yIiIiLM/DxIkTc7xlWPPmzbOsO7vn//Lly8bw4cONkJAQw9nZ2fD19TXq1q1rjB8/3khLS7P0+/PPP42XX37Z8PLyMry9vY2XX37Z+Pnnn3N1y7BMhw4dsvzcb9myxWpeamqqMXToUKNGjRqGp6en4e7ubtSoUcOYOnXqXdeb3e8YV1dXo2bNmsa0adOsboNlGIbxxRdfGBUqVDBcXFyM0NBQY86cOVl+tuLj443WrVsbJUqUMJydnY0SJUoYXbp0yXJ7tbS0NGPs2LFG1apVDRcXF+Oxxx4zwsLCjFGjRhlJSUl3rDunn/NbZXfLMMMwjCNHjhjt27c3fHx8DFdXV6N27drGihUrsix/4sQJo1WrVoabm5vh6+trvPHGG8aaNWuy/d30888/Gy+++KJRrFgxw8XFxShTpozRsWNHIz4+PstzzS3DAJjNzjBuO2YMAAAAAADcF5zTDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmMTR1gUUtIyMDP3xxx/y9PSUnZ2drcsBAAAAADyEDMPQ5cuXVaJECdnb5zye/ciF7j/++ENBQUG2LgMAAAAAUAicOnVKpUqVynH+Ixe6PT09Jd18Yry8vGxcDQAAAADgYZScnKygoCBLxszJIxe6Mw8p9/LyInQDAAAAAO7J3U5b5kJqAAAAAACYhNANAAAAAIBJCN0AAAAAAJjkkTunO7fS09N1/fp1W5cBEzk5OcnBwcHWZQAAAAAoxAjdtzEMQwkJCbp06ZKtS0EB8PHxUUBAAPdsBwAAAGAKQvdtMgO3n5+f3NzcCGOFlGEYunr1qhITEyVJgYGBNq4IAAAAQGFE6L5Fenq6JXAXK1bM1uXAZEWKFJEkJSYmys/Pj0PNAQAAANx3XEjtFpnncLu5udm4EhSUzNea8/cBAAAAmIHQnQ0OKX908FoDAAAAMBOhGwAAAAAAkxC6AQAAAAAwCRdSy6XgYSsLdHvHP2qep/49e/bUvHnzJEmOjo4qVaqUOnTooNGjR8vV1dXSb8WKFfr444+1e/dupaenq2rVqurXr5969uxp6bNx40Y1bNhQFy9elI+Pj9V2goODNXDgQA0cONDStmHDBk2YMEE7duzQ5cuXVbJkSYWHh6tfv3569tlnrdaZnTNnziggICDbeZs2bdLHH3+sXbt26cyZM1q6dKnatGmTp+cGAAAAAGyFke5CpEmTJjpz5oyOHj2qTz75RDNmzFBMTIxl/qeffqrWrVvr6aef1o4dO/TLL7+oc+fOeu211zRkyJB8bXPq1Klq1KiRihUrpri4OB04cEBLly5V3bp1NWjQoCz9Dxw4oDNnzlhNfn5+Oa4/JSVFNWrU0JQpU/JVHwAAAADYEiPdhYiLi4tlxDgoKEiRkZFav369xo4dq1OnTmnw4MEaOHCgxowZY1lm8ODBcnZ21oABA9ShQwdFRETkensnT560jHpPnDjRal716tU1YMCALMv4+fllGT2/k6ZNm6pp06a57g8AAAAADxJGugupX3/9Vdu2bZOzs7MkadGiRbp+/Xq2I9qvvvqqPDw89PXXX+dpG4sXL9b169f15ptvZjufK4MDAAAAeNQRuguRFStWyMPDQ66urqpWrZoSExM1dOhQSdLBgwfl7e2twMDALMs5OzurXLlyOnjwYJ62d/DgQXl5eVmdj7148WJ5eHhYpr1791otU6pUKav5VatWzceeAgAAAMDDgcPLC5GGDRtq2rRpSklJ0SeffCJHR0e1a9fO1G3ePprduHFj7dmzR6dPn1aDBg2Unp5uNX/z5s3y9PS0PHZycrK033oY+YwZM9StWzcTKwcAAAAA8xG6CxF3d3eFhIRIkmbPnq0aNWroiy++UK9evVSxYkUlJSXpjz/+UIkSJayWS0tL05EjRyxXF/fy8pIkJSUlZTn/+tKlS/L29pYkVahQQUlJSUpISLCMdnt4eCgkJESOjtm/tcqWLZvtOd3h4eHas2eP5bG/v3+e9x8AAAAAHjQcXl5I2dvb6+2339a7776ra9euqV27dnJyctKECROy9J0+fbpSUlLUpUsXSTfDtL29vXbt2mXV7+jRo0pKSlLFihUlSe3bt5eTk5PGjh17z/UWKVJEISEhlunW0XAAAAAAeFgx0l2IdejQQUOHDtWUKVM0ZMgQjRs3ToMHD5arq6tefvllOTk56dtvv9Xbb7+twYMHW65c7unpqd69e2vw4MFydHRUtWrVdOrUKb311lt66qmnVLduXUlS6dKlNWHCBL3xxhu6cOGCevbsqbJly+rChQuaP3++JMnBwcGqpsTERP31119WbcWKFbMcZn67K1eu6PDhw5bHx44d0549e1S0aFGVLl36vj1XAAAAAGAGRroLMUdHR/Xv31/jxo1TSkqKBg4cqKVLl2rz5s0KDw/X448/rq+++krTpk3T+PHjrZadPHmyevToobfeektVq1ZVz549Vb16dS1fvtzqPO7XX39d69at07lz59S+fXtVqFBBzZo107Fjx7RmzRpVq1bNar2VKlVSYGCg1XT7iPqtfvrpJ9WqVUu1atWSJEVHR6tWrVoaMWLEfXymAAAAAMAcdoZhGLYuoiAlJyfL29tbSUlJlnOXM/311186duyYypYtK1dXVxtViILEaw4AAAAgP+6ULW/F4eUAUED2hVa2dQkFovL+fbYuAQDwEHsUPi/5rHy0cHg5AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACZxtHUBD42R3gW8vaQ8de/Zs6fmzZsnSXJ0dFSpUqXUoUMHjR49Wq6urpZ+K1as0Mcff6zdu3crPT1dVatWVb9+/dSzZ09Ln40bN6phw4a6ePGifHx8rLYTHBysgQMHauDAgZa2DRs2aMKECdqxY4cuX76skiVLKjw8XP369dOzzz5rtc7snDlzRgEBATnu16VLl7Rs2bI8PR8AAAAA8CBgpLsQadKkic6cOaOjR4/qk08+0YwZMxQTE2OZ/+mnn6p169Z6+umntWPHDv3yyy/q3LmzXnvtNQ0ZMiRf25w6daoaNWqkYsWKKS4uTgcOHNDSpUtVt25dDRo0KEv/AwcO6MyZM1aTn59fvvcZAAAAAB5kjHQXIi4uLpYR46CgIEVGRmr9+vUaO3asTp06pcGDB2vgwIEaM2aMZZnBgwfL2dlZAwYMUIcOHRQREZHr7Z08edIy6j1x4kSredWrV9eAAQOyLOPn55dl9BwAAAAACitGugupX3/9Vdu2bZOzs7MkadGiRbp+/Xq2I9qvvvqqPDw89PXXX+dpG4sXL9b169f15ptvZjvfzs4u74UDAAAAQCFi89A9ZcoUBQcHy9XVVREREdq5c+cd+0+aNEmVKlVSkSJFFBQUpEGDBumvv/4qoGofbCtWrJCHh4dcXV1VrVo1JSYmaujQoZKkgwcPytvbW4GBgVmWc3Z2Vrly5XTw4ME8be/gwYPy8vKyOh978eLF8vDwsEx79+61WqZUqVJW86tWrZqPPQUAAACAh4NNDy+Pi4tTdHS0pk+froiICE2aNEmNGzfWgQMHsj3P96uvvtKwYcM0e/Zs1a1bVwcPHlTPnj1lZ2eX5fDmR1HDhg01bdo0paSk6JNPPpGjo6PatWtn6jZvH81u3Lix9uzZo9OnT6tBgwZKT0+3mr9582Z5enpaHjs5OVnamzZtammfMWOGunXrZmLlAAAAAGA+m4buiRMnqk+fPoqKipIkTZ8+XStXrtTs2bM1bNiwLP23bdump59+Wl27dpV080raXbp00Y4dOwq07geVu7u7QkJCJEmzZ89WjRo19MUXX6hXr16qWLGikpKS9Mcff6hEiRJWy6WlpenIkSOWq4t7eXlJkpKSkrKcf33p0iV5e9+8knuFChWUlJSkhIQEy2i3h4eHQkJC5OiY/VurbNmy2Z7THR4erj179lge+/v753n/AQAAAOBBY7PDy9PS0rRr1y5FRkb+rxh7e0VGRmr79u3ZLlO3bl3t2rXLcgj60aNHtWrVKjVr1izH7aSmpio5OdlqehTY29vr7bff1rvvvqtr166pXbt2cnJy0oQJE7L0nT59ulJSUtSlSxdJN8O0vb29du3aZdXv6NGjSkpKUsWKFSVJ7du3l5OTk8aOHXvP9RYpUkQhISGW6dbRcAAAAAB4WNlspPv8+fNKT0/PMqLp7++v/fv3Z7tM165ddf78eT3zzDMyDEM3btzQa6+9prfffjvH7cTGxmrUqFH3tfaHRYcOHTR06FBNmTJFQ4YM0bhx4zR48GC5urrq5ZdflpOTk7799lu9/fbbGjx4sOXK5Z6enurdu7cGDx4sR0dHVatWTadOndJbb72lp556SnXr1pUklS5dWhMmTNAbb7yhCxcuqGfPnipbtqwuXLig+fPnS5IcHBysakpMTMxyDn6xYsUsh5lnJykpyWoUPHOZoKCge32KAAAAAMBUNr+QWl5s3LhRY8aM0dSpU7V7924tWbJEK1eu1Pvvv5/jMsOHD1dSUpJlOnXqVAFWbFuOjo7q37+/xo0bp5SUFA0cOFBLly7V5s2bFR4erscff1xfffWVpk2bpvHjx1stO3nyZPXo0UNvvfWWqlatqp49e6p69epavny51Xncr7/+utatW6dz586pffv2qlChgpo1a6Zjx45pzZo1qlatmtV6K1WqpMDAQKvp9hH1223cuFG1atWymh7VL1IAAAAAPFzsDMMwbLHhtLQ0ubm5adGiRWrTpo2lvUePHrp06ZK+/fbbLMvUq1dPTz31lD7++GNL2/z58/XKK6/oypUrsre/+3cIycnJ8vb2VlJSkuXc5Ux//fWXjh07prJly8rV1TX/O4eHBq85CtK+0Mq2LqFAVN6/z9YlAAAeYo/C5yWflYXDnbLlrWw20u3s7KywsDDFx8db2jIyMhQfH686depku8zVq1ezBOvMw5dt9N0BAAAAAAA5sunVy6Ojo9WjRw+Fh4erdu3amjRpklJSUixXM+/evbtKliyp2NhYSVLLli01ceJE1apVSxERETp8+LDee+89tWzZMsu5wwAAAAAA2JpNQ3enTp107tw5jRgxQgkJCapZs6bWrFljubjayZMnrUa23333XdnZ2endd9/V6dOnVbx4cbVs2VIffvihrXYBAAAAAIAc2eycblvhnG7citccBelROEdN4jw1AMC9eRQ+L/msLBwe+HO6AQAAAAAo7AjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmMSm9+l+mFSbV61At7e3x9489e/Zs6fmzZtneVy0aFE9+eSTGjdunKpXry5JsrOz09KlS9WmTZssy2/cuFENGzbMdt1nzpxRQECAevbsqUuXLmnZsmXZLnvx4kX5+PjkqW4AAAAAKMwY6S5EmjRpojNnzujMmTOKj4+Xo6OjWrRokad1HDhwwLKOzMnPz8+kigEAAACgcGOkuxBxcXFRQECAJCkgIEDDhg1TvXr1dO7cORUvXjxX6/Dz82O0GgAAAADuE0a6C6krV65o/vz5CgkJUbFixWxdDgAAAAA8khjpLkRWrFghDw8PSVJKSooCAwO1YsUK2dvn/ruVUqVKWT0uU6aMfvvtt/taJwAAAAA8KgjdhUjDhg01bdo0SdLFixc1depUNW3aVDt37lSZMmVytY7NmzfL09PT8tjJycmUWgEAAADgUUDoLkTc3d0VEhJieTxr1ix5e3tr5syZ+uCDD3K1jrJly+Z4TreXl5dOnDiRpf3SpUtycHCQu7t7vuoGAAAAgMKKc7oLMTs7O9nb2+vatWv3ZX2VKlXSb7/9ptTUVKv23bt3q2zZsoyKAwAAAMBtGOkuRFJTU5WQkCDp5uHln332ma5cuaKWLVta+hw7dkx79uyxWq5ChQqW/ycmJuqvv/6yml+sWDE5OTmpW7duGj16tLp3764333xT3t7e2rRpkyZNmqRx48aZt2MAAAAA8JAidBcia9asUWBgoCTJ09NToaGhWrhwoRo0aGDpEx0dnWW5zZs3W/5fqVKlLPO3b9+up556Sj4+Ptq8ebOGDRumVq1aKSkpSSEhIZo4caJ69ep1/3cIAAAAAB5yhO5c2ttjr61LuKO5c+dq7ty5d+xjGMY9zZekihUrasmSJXkpDQAAAAAeWZzTDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJjE0dYFPCz2hVYu0O1V3r8vT/179uypefPmWR4XLVpUTz75pMaNG6fq1atLkuzs7LJd9uuvv1bnzp21ceNGNWzY0NLu6+urJ598UmPHjlW1atVyXD5TTEyMRo4cqaVLl2rs2LHat2+fMjIyVLp0aT3//POaNGlSnvYJAAAAAB52jHQXIk2aNNGZM2d05swZxcfHy9HRUS1atLDqM2fOHEufzKlNmzZWfQ4cOKAzZ85o7dq1Sk1NVfPmzZWWlma1zKRJk+Tl5WXVNmTIEMXHx6tTp05q166ddu7cqV27dunDDz/U9evXTdvv9PR0ZWRkmLZ+AAAAAMgvQnch4uLiooCAAAUEBKhmzZoaNmyYTp06pXPnzln6+Pj4WPpkTq6urlbr8fPzU0BAgJ544gkNHDhQp06d0v79+62W8fb2lp2dnVWbh4eHli9frqefflpDhw5VpUqVVLFiRbVp00ZTpkyx2sby5cv15JNPytXVVb6+vmrbtq1l3sWLF9W9e3c99thjcnNzU9OmTXXo0CHL/Llz58rHx0ffffedqlSpIhcXF508eVKpqakaMmSISpYsKXd3d0VERGjjxo3mPNkAAAAAkAuE7kLqypUrmj9/vkJCQlSsWLF8rSMpKUkLFiyQJDk7O+dqmYCAAP3222/69ddfc+yzcuVKtW3bVs2aNdPPP/+s+Ph41a5d2zK/Z8+e+umnn/Tdd99p+/btMgxDzZo1sxotv3r1qsaOHatZs2bpt99+k5+fn/r376/t27drwYIF+uWXX9ShQwc1adLEKrADAAAAQEHinO5CZMWKFfLw8JAkpaSkKDAwUCtWrJC9/f++W+nSpYscHByslvv9999VunRpy+NSpUpZ1iFJrVq1UmhoaK5qeP3117V582ZVq1ZNZcqU0VNPPaUXXnhB3bp1k4uLiyTpww8/VOfOnTVq1CjLcjVq1JAkHTp0SN999522bt2qunXrSpL++c9/KigoSMuWLVOHDh0kSdevX9fUqVMty508eVJz5szRyZMnVaJECUnSkCFDtGbNGs2ZM0djxozJVf0AAAAAcD8RuguRhg0batq0aZJuHqI9depUNW3aVDt37lSZMmUkSZ988okiIyOtlssMqZk2b94sNzc3/fvf/9aYMWM0ffr0XNfg7u6ulStX6siRI9qwYYP+/e9/a/DgwZo8ebK2b98uNzc37dmzR3369Ml2+X379snR0VERERGWtmLFiqlSpUrat+9/F5dzdna2XCBOkvbu3av09HRVrFjRan2pqan5HukHAAAAgHtF6C5E3N3dFRISYnk8a9YseXt7a+bMmfrggw8k3Tz8+9Y+2Slbtqx8fHxUqVIlJSYmqlOnTtq0aVOeailfvrzKly+v3r1765133lHFihUVFxenqKgoFSlSJO87d5siRYpYXU39ypUrcnBw0K5du7KM5GeO/gMAAABAQeOc7kLMzs5O9vb2unbtWr7X0a9fP/36669aunRpvtcRHBwsNzc3y+Hq1atXV3x8fLZ9K1eurBs3bmjHjh2Wtj///FMHDhxQlSpVctxGrVq1lJ6ersTERIWEhFhNAQEB+a4dAAAAAO4FI92FSGpqqhISEiTdPLz8s88+05UrV9SyZUtLn0uXLln6ZPL09JS7u3u263Rzc1OfPn0UExOjNm3a3PVe3SNHjtTVq1fVrFkzlSlTRpcuXdLf//53Xb9+Xc8//7ykm/fzbtSokcqXL6/OnTvrxo0bWrVqld566y1VqFBBrVu3Vp8+fTRjxgx5enpq2LBhKlmypFq3bp3jditWrKhu3bqpe/fumjBhgmrVqqVz584pPj5e1atXV/PmzXP1HAIAAADA/cRIdyGyZs0aBQYGKjAwUBEREfrxxx+1cOFCNWjQwNInKirK0idz+vTTT++43v79+2vfvn1auHDhXWuoX7++jh49qu7duys0NFRNmzZVQkKC1q1bp0qVKkmSGjRooIULF+q7775TzZo19dxzz2nnzp2WdcyZM0dhYWFq0aKF6tSpI8MwtGrVKjk5Od1x23PmzFH37t01ePBgVapUSW3atNGPP/5odZE4AAAAAChIdoZhGLYuoiAlJyfL29tbSUlJ8vLyspr3119/6dixYypbtmyWe1ejcOI1R0HaF1rZ1iUUiMr79929EwAAOXgUPi/5rCwc7pQtb8VINwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQnc2HrFryz3SeK0BAAAAmInQfYvMW1JdvXrVxpWgoGS+1ne7HRkAAAAA5IejrQt4kDg4OMjHx0eJiYmSJDc3N9nZ2dm4KpjBMAxdvXpViYmJ8vHxkYODg61LAgAAAFAIEbpvExAQIEmW4I3CzcfHx/KaAwAAAMD9Rui+jZ2dnQIDA+Xn56fr16/buhyYyMnJiRFuAAAAAKYidOfAwcGBQAYAAAAAuCdcSA0AAAAAAJM8EKF7ypQpCg4OlqurqyIiIrRz584c+zZo0EB2dnZZpubNmxdgxQAAAAAA3J3NQ3dcXJyio6MVExOj3bt3q0aNGmrcuHGOFzJbsmSJzpw5Y5l+/fVXOTg4qEOHDgVcOQAAAAAAd2bz0D1x4kT16dNHUVFRqlKliqZPny43NzfNnj072/5FixZVQECAZVq/fr3c3NwI3QAAAACAB45NQ3daWpp27dqlyMhIS5u9vb0iIyO1ffv2XK3jiy++UOfOneXu7m5WmQAAAAAA5ItNr15+/vx5paeny9/f36rd399f+/fvv+vyO3fu1K+//qovvvgixz6pqalKTU21PE5OTs5/wQAAAAAA5IHNDy+/F1988YWqVaum2rVr59gnNjZW3t7elikoKKgAKwQAAAAAPMpsGrp9fX3l4OCgs2fPWrWfPXtWAQEBd1w2JSVFCxYsUK9eve7Yb/jw4UpKSrJMp06duue6AQAAAADIDZuGbmdnZ4WFhSk+Pt7SlpGRofj4eNWpU+eOyy5cuFCpqal66aWX7tjPxcVFXl5eVhMAAAAAAAXBpud0S1J0dLR69Oih8PBw1a5dW5MmTVJKSoqioqIkSd27d1fJkiUVGxtrtdwXX3yhNm3aqFixYrYoGwAAAACAu7J56O7UqZPOnTunESNGKCEhQTVr1tSaNWssF1c7efKk7O2tB+QPHDigLVu2aN26dbYoGQAAAACAXLEzDMOwdREFKTk5Wd7e3kpKSuJQcwAFal9oZVuXUCAq799n6xIAAA+xR+Hzks/KwiG32fKhvno5AAAAAAAPMkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEpuH7ilTpig4OFiurq6KiIjQzp0779j/0qVL6tevnwIDA+Xi4qKKFStq1apVBVQtAAAAAAC552jLjcfFxSk6OlrTp09XRESEJk2apMaNG+vAgQPy8/PL0j8tLU3PP/+8/Pz8tGjRIpUsWVInTpyQj49PwRcPAAAAAMBd2DR0T5w4UX369FFUVJQkafr06Vq5cqVmz56tYcOGZek/e/ZsXbhwQdu2bZOTk5MkKTg4uCBLBgAAAAAg12x2eHlaWpp27dqlyMjI/xVjb6/IyEht374922W+++471alTR/369ZO/v78ef/xxjRkzRunp6QVVNgAAAAAAuWazke7z588rPT1d/v7+Vu3+/v7av39/tsscPXpU//rXv9StWzetWrVKhw8fVt++fXX9+nXFxMRku0xqaqpSU1Mtj5OTk+/fTgAAAAAAcAc2v5BaXmRkZMjPz0+ff/65wsLC1KlTJ73zzjuaPn16jsvExsbK29vbMgUFBRVgxQAAAACAR5nNQrevr68cHBx09uxZq/azZ88qICAg22UCAwNVsWJFOTg4WNoqV66shIQEpaWlZbvM8OHDlZSUZJlOnTp1/3YCAAAAAIA7sFnodnZ2VlhYmOLj4y1tGRkZio+PV506dbJd5umnn9bhw4eVkZFhaTt48KACAwPl7Oyc7TIuLi7y8vKymgAAAAAAKAg2Pbw8OjpaM2fO1Lx587Rv3z793//9n1JSUixXM+/evbuGDx9u6f9///d/unDhgt544w0dPHhQK1eu1JgxY9SvXz9b7QIAAAAAADmy6S3DOnXqpHPnzmnEiBFKSEhQzZo1tWbNGsvF1U6ePCl7+/99LxAUFKS1a9dq0KBBql69ukqWLKk33nhDb731lq12AQAAAACAHNkZhmHYuoiClJycLG9vbyUlJXGoOYACtS+0sq1LKBCV9++zdQkAgIfYo/B5yWdl4ZDbbPlQXb0cAAAAAICHCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwyQMRuqdMmaLg4GC5uroqIiJCO3fuzLHv3LlzZWdnZzW5uroWYLUAAAAAAOSOzUN3XFycoqOjFRMTo927d6tGjRpq3LixEhMTc1zGy8tLZ86csUwnTpwowIoBAAAAAMgdm4fuiRMnqk+fPoqKilKVKlU0ffp0ubm5afbs2TkuY2dnp4CAAMvk7+9fgBUDAAAAAJA7Ng3daWlp2rVrlyIjIy1t9vb2ioyM1Pbt23Nc7sqVKypTpoyCgoLUunVr/fbbbwVRLgAAAAAAeWLT0H3+/Hmlp6dnGan29/dXQkJCtstUqlRJs2fP1rfffqv58+crIyNDdevW1X//+99s+6empio5OdlqAgAAAACgINj88PK8qlOnjrp3766aNWuqfv36WrJkiYoXL64ZM2Zk2z82Nlbe3t6WKSgoqIArBgAAAAA8qmwaun19feXg4KCzZ89atZ89e1YBAQG5WoeTk5Nq1aqlw4cPZzt/+PDhSkpKskynTp2657oBAAAAAMgNm4ZuZ2dnhYWFKT4+3tKWkZGh+Ph41alTJ1frSE9P1969exUYGJjtfBcXF3l5eVlNAAAAAAAUBEdbFxAdHa0ePXooPDxctWvX1qRJk5SSkqKoqChJUvfu3VWyZEnFxsZKkkaPHq2nnnpKISEhunTpkj7++GOdOHFCvXv3tuVuAAAAAACQhc1Dd6dOnXTu3DmNGDFCCQkJqlmzptasWWO5uNrJkydlb/+/AfmLFy+qT58+SkhI0GOPPaawsDBt27ZNVapUsdUuAAAAAACQLTvDMAxbF1GQkpOT5e3traSkJA41B1Cg9oVWtnUJBaLy/n22LgEA8BB7FD4v+awsHHKbLR+6q5cDAAAAAPCwIHQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACa5p9CdlpamAwcO6MaNG/erHgAAAAAACo18he6rV6+qV69ecnNzU9WqVXXy5ElJ0uuvv66PPvrovhYIAAAAAMDDKl+he/jw4frPf/6jjRs3ytXV1dIeGRmpuLi4+1YcAAAAAAAPM8f8LLRs2TLFxcXpqaeekp2dnaW9atWqOnLkyH0rDgAAAACAh1m+RrrPnTsnPz+/LO0pKSlWIRwAAAAAgEdZvkJ3eHi4Vq5caXmcGbRnzZqlOnXq3J/KAAAAAAB4yOXr8PIxY8aoadOm+v3333Xjxg1NnjxZv//+u7Zt26YffvjhftcIAAAAAMBDKV8j3c8884z+85//6MaNG6pWrZrWrVsnPz8/bd++XWFhYfe7RgAAAAAAHkp5Hum+fv26Xn31Vb333nuaOXOmGTUBAAAAAFAo5Hmk28nJSYsXLzajFgAAAAAACpV8HV7epk0bLVu27D6XAgAAAABA4ZKvC6lVqFBBo0eP1tatWxUWFiZ3d3er+QMGDLgvxQEAAAAA8DDLV+j+4osv5OPjo127dmnXrl1W8+zs7AjdAAAAAAAon6H72LFj97sOAAAAAAAKnXyd030rwzBkGMb9qAUAAAAAgEIl36H7H//4h6pVq6YiRYqoSJEiql69ur788sv7WRsAAAAAAA+1fB1ePnHiRL333nvq37+/nn76aUnSli1b9Nprr+n8+fMaNGjQfS0SAAAAAICHUb5C96effqpp06ape/fulrZWrVqpatWqGjlyJKEbAAAAAADl8/DyM2fOqG7dulna69atqzNnztxzUQAAAAAAFAb5Ct0hISH65ptvsrTHxcWpQoUK91wUAAAAAACFQb4OLx81apQ6deqkTZs2Wc7p3rp1q+Lj47MN4wAAAAAAPIryNdLdrl077dixQ76+vlq2bJmWLVsmX19f7dy5U23btr3fNQIAAAAA8FDK10i3JIWFhWn+/Pn3sxYAAAAAAAqVfI10r1q1SmvXrs3SvnbtWq1evfqeiwIAAAAAoDDIV+geNmyY0tPTs7QbhqFhw4bdc1EAAAAAABQG+Qrdhw4dUpUqVbK0h4aG6vDhw/dcFAAAAAAAhUG+Qre3t7eOHj2apf3w4cNyd3e/56IAAAAAACgM8hW6W7durYEDB+rIkSOWtsOHD2vw4MFq1arVfSsOAAAAAICHWb5C97hx4+Tu7q7Q0FCVLVtWZcuWVWhoqIoVK6bx48ff7xoBAAAAAHgo5euWYd7e3tq2bZvWr1+v//znPypSpIhq1KihevXq3e/6AAAAAAB4aOVppHv79u1asWKFJMnOzk4vvPCC/Pz8NH78eLVr106vvPKKUlNTTSkUAAAAAICHTZ5C9+jRo/Xbb79ZHu/du1d9+vTR888/r2HDhmn58uWKjY2970UCAAAAAPAwylPo3rNnjxo1amR5vGDBAtWuXVszZ85UdHS0/v73v+ubb76570UCAAAAAPAwylPovnjxovz9/S2Pf/jhBzVt2tTy+Mknn9SpU6fuX3UAAAAAADzE8hS6/f39dezYMUlSWlqadu/eraeeesoy//Lly3JycspzEVOmTFFwcLBcXV0VERGhnTt35mq5BQsWyM7OTm3atMnzNgEAAAAAMFueQnezZs00bNgwbd68WcOHD5ebm5vVFct/+eUXlS9fPk8FxMXFKTo6WjExMdq9e7dq1Kihxo0bKzEx8Y7LHT9+XEOGDOGK6QAAAACAB1aeQvf7778vR0dH1a9fXzNnztTMmTPl7OxsmT979my98MILeSpg4sSJ6tOnj6KiolSlShVNnz5dbm5umj17do7LpKenq1u3bho1apTKlSuXp+0BAAAAAFBQ8nSfbl9fX23atElJSUny8PCQg4OD1fyFCxfKw8Mj1+tLS0vTrl27NHz4cEubvb29IiMjtX379hyXGz16tPz8/NSrVy9t3rw5L7sAAAAAAECByVPozuTt7Z1te9GiRfO0nvPnzys9Pd3q4mzSzXPH9+/fn+0yW7Zs0RdffKE9e/bkahupqalW9w5PTk7OU40AAAAAAORXng4vt7XLly/r5Zdf1syZM+Xr65urZWJjY+Xt7W2ZgoKCTK4SAAAAAICb8jXSfb/4+vrKwcFBZ8+etWo/e/asAgICsvQ/cuSIjh8/rpYtW1raMjIyJEmOjo46cOBAlgu5DR8+XNHR0ZbHycnJBG8AAAAAQIGwaeh2dnZWWFiY4uPjLbf9ysjIUHx8vPr375+lf2hoqPbu3WvV9u677+ry5cuaPHlytmHaxcVFLi4uptQPAAAAAMCd2DR0S1J0dLR69Oih8PBw1a5dW5MmTVJKSoqioqIkSd27d1fJkiUVGxsrV1dXPf7441bL+/j4SFKWdgAAAAAAbM3mobtTp046d+6cRowYoYSEBNWsWVNr1qyxXFzt5MmTsrd/qE49BwAAAABAkmRnGIZh6yIKUnJysry9vZWUlCQvLy9blwPgEbIvtLKtSygQlffvs3UJAICH2KPweclnZeGQ22zJEDIAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACZ5IEL3lClTFBwcLFdXV0VERGjnzp059l2yZInCw8Pl4+Mjd3d31axZU19++WUBVgsAAAAAQO7YPHTHxcUpOjpaMTEx2r17t2rUqKHGjRsrMTEx2/5FixbVO++8o+3bt+uXX35RVFSUoqKitHbt2gKuHAAAAACAO7N56J44caL69OmjqKgoValSRdOnT5ebm5tmz56dbf8GDRqobdu2qly5ssqXL6833nhD1atX15YtWwq4cgAAAAAA7symoTstLU27du1SZGSkpc3e3l6RkZHavn37XZc3DEPx8fE6cOCAnn32WTNLBQAAAAAgzxxtufHz588rPT1d/v7+Vu3+/v7av39/jsslJSWpZMmSSk1NlYODg6ZOnarnn38+276pqalKTU21PE5OTr4/xQMAAAAAcBc2Dd355enpqT179ujKlSuKj49XdHS0ypUrpwYNGmTpGxsbq1GjRhV8kQAAAACAR55NQ7evr68cHBx09uxZq/azZ88qICAgx+Xs7e0VEhIiSapZs6b27dun2NjYbEP38OHDFR0dbXmcnJysoKCg+7MDAAAAAADcgU3P6XZ2dlZYWJji4+MtbRkZGYqPj1edOnVyvZ6MjAyrQ8hv5eLiIi8vL6sJAAAAAICCYPPDy6Ojo9WjRw+Fh4erdu3amjRpklJSUhQVFSVJ6t69u0qWLKnY2FhJNw8XDw8PV/ny5ZWamqpVq1bpyy+/1LRp02y5GwAAAAAAZGHz0N2pUyedO3dOI0aMUEJCgmrWrKk1a9ZYLq528uRJ2dv/b0A+JSVFffv21X//+18VKVJEoaGhmj9/vjp16mSrXQAAAAAAIFt2hmEYti6iICUnJ8vb21tJSUkcag6gQO0LrWzrEgpE5f37bF0CAOAh9ih8XvJZWTjkNlva9JxuAAAAAAAKM0I3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASR1sXAAAAAPMED1tp6xIKxPGPmtu6BADIFqEbDzX+kAAAAADwIOPwcgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABM8kCE7ilTpig4OFiurq6KiIjQzp07c+w7c+ZM1atXT4899pgee+wxRUZG3rE/AAAAAAC2YvPQHRcXp+joaMXExGj37t2qUaOGGjdurMTExGz7b9y4UV26dNGGDRu0fft2BQUF6YUXXtDp06cLuHIAAAAAAO7M5qF74sSJ6tOnj6KiolSlShVNnz5dbm5umj17drb9//nPf6pv376qWbOmQkNDNWvWLGVkZCg+Pr6AKwcAAAAA4M5sGrrT0tK0a9cuRUZGWtrs7e0VGRmp7du352odV69e1fXr11W0aNFs56empio5OdlqAgAAAACgINg0dJ8/f17p6eny9/e3avf391dCQkKu1vHWW2+pRIkSVsH9VrGxsfL29rZMQUFB91w3AAAAAAC5YfPDy+/FRx99pAULFmjp0qVydXXNts/w4cOVlJRkmU6dOlXAVQIAAAAAHlWOtty4r6+vHBwcdPbsWav2s2fPKiAg4I7Ljh8/Xh999JG+//57Va9ePcd+Li4ucnFxuS/1AgAAAACQFzYd6XZ2dlZYWJjVRdAyL4pWp06dHJcbN26c3n//fa1Zs0bh4eEFUSoAAAAAAHlm05FuSYqOjlaPHj0UHh6u2rVra9KkSUpJSVFUVJQkqXv37ipZsqRiY2MlSWPHjtWIESP01VdfKTg42HLut4eHhzw8PGy2HwAAAAAA3M7mobtTp046d+6cRowYoYSEBNWsWVNr1qyxXFzt5MmTsrf/34D8tGnTlJaWpvbt21utJyYmRiNHjizI0gEAAAAAuCObh25J6t+/v/r375/tvI0bN1o9Pn78uPkFAQAAAABwHzzUVy8HAAAAAOBBRugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSOti4AAAAAuGcjvW1dgflGJtm6AgD5QOgGHgb8IQEAAAA8lDi8HAAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAk9g8dE+ZMkXBwcFydXVVRESEdu7cmWPf3377Te3atVNwcLDs7Ow0adKkgisUAAAAAIA8smnojouLU3R0tGJiYrR7927VqFFDjRs3VmJiYrb9r169qnLlyumjjz5SQEBAAVcLAAAAAEDe2DR0T5w4UX369FFUVJSqVKmi6dOny83NTbNnz862/5NPPqmPP/5YnTt3louLSwFXCwAAAABA3tgsdKelpWnXrl2KjIz8XzH29oqMjNT27dvv23ZSU1OVnJxsNQEAAAAAUBBsFrrPnz+v9PR0+fv7W7X7+/srISHhvm0nNjZW3t7elikoKOi+rRsAAAAAgDux+YXUzDZ8+HAlJSVZplOnTtm6JAAAAADAI8LRVhv29fWVg4ODzp49a9V+9uzZ+3qRNBcXF87/BgAAAADYhM1Gup2dnRUWFqb4+HhLW0ZGhuLj41WnTh1blQUAAAAAwH1js5FuSYqOjlaPHj0UHh6u2rVra9KkSUpJSVFUVJQkqXv37ipZsqRiY2Ml3bz42u+//275/+nTp7Vnzx55eHgoJCTEZvsBAAAAAEB2bBq6O3XqpHPnzmnEiBFKSEhQzZo1tWbNGsvF1U6ePCl7+/8Nxv/xxx+qVauW5fH48eM1fvx41a9fXxs3bizo8gEAAAAAuCObhm5J6t+/v/r375/tvNuDdHBwsAzDKICqAAAAAAC4d4X+6uUAAAAAANgKoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADCJo60LAAAAAHB31eZVs3UJBeIbWxcA3GeEbgAPhEfhDwn+iAAAAHj0cHg5AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYJIHInRPmTJFwcHBcnV1VUREhHbu3HnH/gsXLlRoaKhcXV1VrVo1rVq1qoAqBQAAAAAg92weuuPi4hQdHa2YmBjt3r1bNWrUUOPGjZWYmJht/23btqlLly7q1auXfv75Z7Vp00Zt2rTRr7/+WsCVAwAAAABwZzYP3RMnTlSfPn0UFRWlKlWqaPr06XJzc9Ps2bOz7T958mQ1adJEQ4cOVeXKlfX+++/riSee0GeffVbAlQMAAAAAcGeOttx4Wlqadu3apeHDh1va7O3tFRkZqe3bt2e7zPbt2xUdHW3V1rhxYy1btizb/qmpqUpNTbU8TkpKkiQlJyffY/V4EGSkXrV1CQUi2c6wdQmmS7+WbusSTHclvfDvo8TvV+BBw2dl4fEofFZKj8bnJZ+VhUPm62gYd/79Y9PQff78eaWnp8vf39+q3d/fX/v37892mYSEhGz7JyQkZNs/NjZWo0aNytIeFBSUz6qBgudt6wIKxD5bF2C62rYuoKB4PxrvWAAPlkfjN0/h/6yUHpHPSz4rC5XLly/L+w6vqU1Dd0EYPny41ch4RkaGLly4oGLFisnOzs6GlQHIlJycrKCgIJ06dUpeXl62LgcAgAcOn5XAg8cwDF2+fFklSpS4Yz+bhm5fX185ODjo7NmzVu1nz55VQEBAtssEBATkqb+Li4tcXFys2nx8fPJfNADTeHl58YcEAAB3wGcl8GC50wh3JpteSM3Z2VlhYWGKj4+3tGVkZCg+Pl516tTJdpk6depY9Zek9evX59gfAAAAAABbsfnh5dHR0erRo4fCw8NVu3ZtTZo0SSkpKYqKipIkde/eXSVLllRsbKwk6Y033lD9+vU1YcIENW/eXAsWLNBPP/2kzz//3Ja7AQAAAABAFjYP3Z06ddK5c+c0YsQIJSQkqGbNmlqzZo3lYmknT56Uvf3/BuTr1q2rr776Su+++67efvttVahQQcuWLdPjjz9uq10AcI9cXFwUExOT5VQQAABwE5+VwMPLzrjb9c0BAAAAAEC+2PScbgAAAAAACjNCNwAAAAAAJiF0AwAAAABgEkI3gCwaNGiggQMH2rqMArdx40bZ2dnp0qVLti4FAAAAhQShG3iE9ezZU3Z2dlmmcePG6f333zd9+49quAcAPLpu/+wtVqyYmjRpol9++cXWpQEwCaEbeMQ1adJEZ86csZrCwsLk6elp69IAACiUbv3sjY+Pl6Ojo1q0aGHrsgCYhNANPOJcXFwUEBBgNTVq1MhqBDo4OFhjxozR3/72N3l6eqp06dL6/PPPrdZz6tQpdezYUT4+PipatKhat26t48eP57jdnj176ocfftDkyZMt3/YfP35cc+fOlY+Pj1XfZcuWyc7OzvJ45MiRqlmzpr788ksFBwfL29tbnTt31uXLly19MjIyFBsbq7Jly6pIkSKqUaOGFi1aZLXeVatWqWLFiipSpIgaNmx4x3oBALhfbv3srVmzpoYNG6ZTp07p3LlzkqS33npLFStWlJubm8qVK6f33ntP169ftyz/n//8Rw0bNpSnp6e8vLwUFhamn376yTJ/y5YtqlevnooUKaKgoCANGDBAKSkpBb6fAG4idAPIlQkTJig8PFw///yz+vbtq//7v//TgQMHJEnXr19X48aN5enpqc2bN2vr1q3y8PBQkyZNlJaWlu36Jk+erDp16qhPnz6Wb/uDgoJyXc+RI0e0bNkyrVixQitWrNAPP/ygjz76yDI/NjZW//jHPzR9+nT99ttvGjRokF566SX98MMPkm5+SfDiiy+qZcuW2rNnj3r37q1hw4bdwzMEAEDeXblyRfPnz1dISIiKFSsmSfL09NTcuXP1+++/a/LkyZo5c6Y++eQTyzLdunVTqVKl9OOPP2rXrl0aNmyYnJycJN38fGzSpInatWunX375RXFxcdqyZYv69+9vk/0DIDnaugAAtrVixQp5eHhYHjdt2jTbfs2aNVPfvn0l3fwG/pNPPtGGDRtUqVIlxcXFKSMjQ7NmzbKMSM+ZM0c+Pj7auHGjXnjhhSzr8/b2lrOzs9zc3BQQEJDnujMyMjR37lzLYfAvv/yy4uPj9eGHHyo1NVVjxozR999/rzp16kiSypUrpy1btmjGjBmqX7++pk2bpvLly2vChAmSpEqVKmnv3r0aO3ZsnmsBACAvbv3sTUlJUWBgoFasWCF7+5vjYe+++66lb3BwsIYMGaIFCxbozTfflCSdPHlSQ4cOVWhoqCSpQoUKlv6xsbHq1q2b5Yi1ChUq6O9//7vls8/V1bUgdhHALQjdwCOuYcOGmjZtmuWxu7u7unTpkqVf9erVLf+3s7NTQECAEhMTJd08zO3w4cNZzgP/66+/dOTIEW3evNkqzM+YMUPdunW7p7qDg4OtthcYGGip5/Dhw7p69aqef/55q2XS0tJUq1YtSdK+ffsUERFhNT8zoAMAYKZbP3svXryoqVOnqmnTptq5c6fKlCmjuLg4/f3vf9eRI0d05coV3bhxQ15eXpblo6Oj1bt3b3355ZeKjIxUhw4dVL58eUk3P5N/+eUX/fOf/7T0NwxDGRkZOnbsmCpXrlywOwuA0A086tzd3RUSEnLXfpmHrWWys7NTRkaGpJuHxoWFhVl9wGcqXry4nJ2dtWfPHkubv79/jtuxt7eXYRhWbbeex5bbeiRp5cqVKlmypFU/FxeXHLcNAEBBuP2zd9asWfL29tbMmTPVvHlzdevWTaNGjVLjxo3l7e2tBQsWWI7Mkm5e26Rr165auXKlVq9erZiYGC1YsEBt27bVlStX9Oqrr2rAgAFZtlu6dOkC2T8A1gjdAO7ZE088obi4OPn5+Vl9E3+r7IK9s7Oz0tPTrdqKFy+uy5cvKyUlRe7u7pJkFdhzo0qVKnJxcdHJkydVv379bPtUrlxZ3333nVXbv//97zxtBwCA+8HOzk729va6du2atm3bpjJlyuidd96xzD9x4kSWZSpWrKiKFStq0KBB6tKli+bMmaO2bdvqiSee0O+//56rL9QBFAwupAbgnnXr1k2+vr5q3bq1Nm/erGPHjmnjxo0aMGCA/vvf/+a4XHBwsHbs2KHjx4/r/PnzysjIUEREhNzc3PT222/ryJEj+uqrrzR37tw81ePp6akhQ4Zo0KBBmjdvno4cOaLdu3fr008/1bx58yRJr732mg4dOqShQ4fqwIED+doOAAD5kZqaqoSEBCUkJGjfvn16/fXXdeXKFbVs2VIVKlTQyZMntWDBAh05ckR///vftXTpUsuy165dU//+/bVx40adOHFCW7du1Y8//mg5bPytt97Stm3b1L9/f+3Zs0eHDh3St99+y4XUABsidAO4Z25ubtq0aZNKly6tF198UZUrV1avXr30119/5TjyLUlDhgyRg4ODqlSpouLFi+vkyZMqWrSo5s+fr1WrVqlatWr6+uuvNXLkyDzX9P777+u9995TbGysKleurCZNmmjlypUqW7aspJuH2C1evFjLli1TjRo1NH36dI0ZMya/TwEAALm2Zs0aBQYGKjAwUBEREfrxxx+1cOFCNWjQQK1atdKgQYPUv39/1axZU9u2bdN7771nWdbBwUF//vmnunfvrooVK6pjx45q2rSpRo0aJenmNVh++OEHHTx4UPXq1VOtWrU0YsQIlShRwla7Czzy7IzbT54EAAAAAAD3BSPdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASf4fFJwT+vuFPj8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results, index=labels)\n",
    "df_results.plot(kind=\"bar\", figsize=(10,6))\n",
    "plt.title(\"Evaluation Metrics: Fine-tuned vs Base Model\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"evaluation_bar_chart.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21afbdfc-fa21-415b-8832-8ecb16d332aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ROUGE-1   ROUGE-L      BLEU  BERTScore\n",
      "Fine-tuned  0.273244  0.140273  0.025094   0.830307\n",
      "Base        0.274378  0.141729  0.026383   0.830307\n"
     ]
    }
   ],
   "source": [
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7dcd81-ea59-40b5-a236-ab7efd0086ba",
   "metadata": {},
   "source": [
    "# Part 4B: LLM-as-a-Judge Evaluation (Together.ai API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee841180-d9b2-46de-896d-74734bf0fbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6483dfc4-d013-4b89-8b0c-8449913d7cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    api_key=\"381c3a2dddc050a80df691423e856e9a2334fda9cc28c2a790d04144bf02ddee\",  \n",
    "    base_url=\"https://api.together.xyz/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7345dbba-493a-4099-910f-a672f1cd8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_model = \"deepseek-ai/DeepSeek-V3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b317b976-da03-4e7c-a90b-6bf67703ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"summaries_comparison.csv\")\n",
    "\n",
    "# Randomly select 10 samples\n",
    "samples = df.sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd875c57-3ba9-4827-82c6-b9316ca9b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(input_text, summary, max_chars=4000):\n",
    "    # Truncate input to avoid context window errors\n",
    "    input_text = input_text[:max_chars]\n",
    "    return f\"\"\"\n",
    "Given the following input and the summary produced, evaluate the summary on:\n",
    "1. Fluency (Is the summary readable and grammatically correct?)\n",
    "2. Factuality (Are the statements in the summary correct, and do they reflect the source?)\n",
    "3. Coverage (Does the summary include the main problem, method, and key findings?)\n",
    "\n",
    "Use a score from 1 (poor) to 5 (excellent) for each. Provide a short justification for each score.\n",
    "\n",
    "Input: {input_text}\n",
    "Generated Summary: {summary}\n",
    "\n",
    "Respond in this format:\n",
    "Fluency: [score] - [justification]\n",
    "Factuality: [score] - [justification]\n",
    "Coverage: [score] - [justification]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f205009c-72e4-4958-917b-218949f5d559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating sample 9/10...\n",
      "Fluency: 3 - The summary is mostly readable and grammatically correct, but it includes repetitive and nonsensical lines (e.g., the repeated \"@xmathX kev feature was detected by _ xmm - newton_@xcite\"), which disrupt the flow and clarity.  \n",
      "\n",
      "Factuality: 4 - The summary accurately reflects the source material for the most part, but the repetitive and incorrect additions (e.g., the \"@xmathX kev feature\" lines) introduce factual inaccuracies not present in the original text.  \n",
      "\n",
      "Coverage: 2 - The summary captures some key points (e.g., the challenge of determining neutron star properties, the role of atmospheres, and the case of 1e1207.4-5209), but it misses critical details (e.g., the debate over non-hydrogen atmospheres, the significance of the spectral features, and the proposed interpretations). The repetitive and irrelevant lines further detract from coverage.\n",
      "Evaluating sample 2/10...\n",
      "Fluency: 5 - The summary is highly readable and grammatically correct, with clear and coherent sentences that flow well.  \n",
      "\n",
      "Factuality: 4 - The summary accurately reflects the source, but there is a minor factual error regarding the telescope used (the source mentions the 3.8 m UK Infrared Telescope, not a 2.2-2.8m telescope in India). Otherwise, the key details are correct.  \n",
      "\n",
      "Coverage: 4 - The summary covers the main problem (the nature of V4332 Sgr's eruption), methods (infrared observations), and key findings (unexpected water-ice detection, new eruptive object class). However, it omits some finer details like the black-body temperature and dust shell formation specifics.\n",
      "Evaluating sample 6/10...\n",
      "Fluency: 3 - The summary is mostly readable and grammatically correct, but it contains some awkward phrasing and incomplete sentences (e.g., \"this criticism is based on the fact that the @xmath17 scaling form does not take into account the temperature dependence of the normalization constant, @xmath33, for each observable.\"). The use of placeholders like @xmath33 also disrupts readability.\n",
      "\n",
      "Factuality: 4 - The summary accurately reflects the source material, including the discussion of @xmath17 and @xmath24 scaling, critical exponents, and normalization factors. However, it introduces a minor inaccuracy by stating \"@xmath17 scaling has been widely used in the analysis of numerical data\" without explicitly linking this to the source's context.\n",
      "\n",
      "Coverage: 3 - The summary covers the main problem (scaling conventions) and methods (@xmath17 and @xmath24 scaling), but it misses key findings, such as the proposed extended scaling scheme and its validation using ferromagnets. The summary also ends abruptly, omitting the conclusion or broader implications.\n",
      "Evaluating sample 1/10...\n",
      "Fluency: 3 - The summary is mostly readable and grammatically correct, but it contains some awkward phrasing and incomplete sentences (e.g., \"as@xmath0 polycrystalline sample, measured in a magnetic field of 1 mt. superconductivity sets in at @xmath11 k.]\"). The use of placeholders like \"@xmath0\" and \"@xmath11\" also disrupts readability.  \n",
      "\n",
      "Factuality: 4 - The summary accurately reflects the source material, including details about superconductivity in iron oxyarsenides, the synthesis of rbfe@xmath0as@xmath0, and its properties. However, it includes an unsupported claim about the crystal structure being confirmed by single-crystal X-ray diffraction (not mentioned in the input), which slightly detracts from factuality.  \n",
      "\n",
      "Coverage: 4 - The summary covers the main problem (superconductivity in rbfe@xmath0as@xmath0), the method (two-step synthesis), and key findings (onset of superconductivity at 11 K, magnetic properties). However, it misses some finer details like the upper critical field estimation and the paramagnetic response in the normal state, which are important in the input.\n",
      "Evaluating sample 8/10...\n",
      "Fluency: 1 - The summary is not readable or grammatically correct. It includes repeated and nonsensical text (e.g., \"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\"), which disrupts coherence and understanding.  \n",
      "\n",
      "Factuality: 3 - The summary correctly reproduces some factual statements from the source (e.g., the analysis of electromagnetic corrections, the role of chiral lagrangians, and the challenges of the methodology). However, the inclusion of nonsensical text and the lack of proper structure reduce its reliability.  \n",
      "\n",
      "Coverage: 2 - The summary partially covers the main problem (electromagnetic corrections to kaon decays) and mentions the method (ch\n",
      "Evaluating sample 3/10...\n",
      "Fluency: 3 - The summary is mostly readable and grammatically correct, but it includes some incomplete sentences and abrupt transitions (e.g., \"the rmf approach is based on the mean - field approximation, where the nucleon - nucleon and nucleon - hyperon interactions are taken into account, but the nucleon - hyperon and hyperon - hyperon\" is cut off).  \n",
      "\n",
      "Factuality: 4 - The summary accurately reflects the source, including key points about neutron stars, hybrid stars, and the models used (e.g., NLW and NJL). However, it introduces a new claim (\"it is our aim to show...\") that is not explicitly stated in the input, which slightly deviates from strict factuality.  \n",
      "\n",
      "Coverage: 4 - The summary covers the main problem (understanding neutron/hybrid stars), methods (EOS, TOV equations, and specific models), and key findings (uncertainties in composition, mixed phase debate). However, it omits some details about observational constraints and the critique of the MIT bag model, which are important in the original text.\n",
      "Evaluating sample 10/10...\n",
      "Fluency: 4 - The summary is highly readable and grammatically correct, with only minor issues like the abrupt ending (\"the electrostatic interactions between the adsorbed halide atoms and the\"). The flow and coherence are strong, making it easy to follow.  \n",
      "\n",
      "Factuality: 5 - The summary accurately reflects the source text, capturing key details about lateral interactions, the focus on chlorine adsorption, the limitations of the lattice-gas model, and the proposed self-consistent approach. No factual inaccuracies are present.  \n",
      "\n",
      "Coverage: 4 - The summary covers the main problem (understanding lateral interactions for Cl/Ag(100)), the method (lattice-gas model with variable parameters), and key findings (insufficiency of constant parameters for Cl/Ag(100)). However, it omits minor details like the Monte Carlo methods and experimental procedure, and the ending is truncated.\n",
      "Evaluating sample 5/10...\n",
      "Fluency: 3 - The summary is mostly readable and grammatically correct, but it contains some awkward phrasing and repetition (e.g., \"taken into account\" is repeated multiple times). The use of placeholders like @xmath0 and @xcite also disrupts readability, though this is likely due to the source format.  \n",
      "\n",
      "Factuality: 2 - The summary includes some correct information from the source, but it also introduces inaccuracies and inconsistencies. For example, it misrepresents the pseudoscalar states (e.g., @xmath30 and @xmath31 are incorrectly listed as pseudoscalars, and the summary repeats the same structure for unrelated decays). The summary also omits key details from the source, such as the role of the VMD model and the specific findings about @xmath8-@xmath9 mixing.  \n",
      "\n",
      "Coverage: 2 - The summary partially covers the main problem (differences in decay patterns between @xmath0 and @xmath1) and mentions some methods (e.g., QCD sum rules, mixing effects), but it fails to coherently summarize the key findings or the proposed solution (the VMD model). It also includes irrelevant repetitions (e.g., the redundant listing\n",
      "Evaluating sample 4/10...\n",
      "Fluency: 3 - The summary is mostly readable and grammatically correct, but it contains some awkward phrasing (e.g., \"this paper unfolds as follows\" followed by redundant repetition of the paper's structure). The repetition of sections and lack of smooth transitions reduce fluency.  \n",
      "\n",
      "Factuality: 4 - The summary accurately reflects the source, including key details about quantum fluids, experimental examples, and the paper's focus on structure effects. However, minor inaccuracies (e.g., redundant section descriptions) slightly detract from factuality.  \n",
      "\n",
      "Coverage: 4 - The summary covers the main problem (effects of periodic structures on quantum gases), method (modeling with delta potentials and calculating thermodynamic properties), and key findings (comparison with literature). However, it misses some technical specifics (e.g., the transcendental equation for energy) and includes redundant organizational details.\n",
      "Evaluating sample 7/10...\n",
      "Fluency: 3 - The summary is mostly readable and grammatically correct, but it contains repetitive phrases (e.g., \"in the type - ii seesaw, the heavy right - handed neutrinos are introduced...\") and lacks smooth transitions between ideas.  \n",
      "\n",
      "Factuality: 4 - The summary accurately reflects the source material, but it misrepresents the type-II seesaw mechanism by incorrectly stating that heavy right-handed neutrinos do not contribute to light-neutrino masses (they are not part of type-II seesaw, which instead introduces a Higgs triplet).  \n",
      "\n",
      "Coverage: 3 - The summary covers the main problem (neutrino mass generation) and some methods (seesaw mechanisms), but it misses key findings (e.g., the role of extra dimensions, KK states, and non-unitary mixing in the proposed model) and repeats information without advancing the discussion.\n",
      "Saved results to llm_judge_results_deepseek.csv\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for idx, row in samples.iterrows():\n",
    "    prompt = build_prompt(row[\"input\"], row[\"finetuned_summary\"])\n",
    "    print(f\"Evaluating sample {idx+1}/10...\")\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=judge_model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=256,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        judgement = response.choices[0].message.content\n",
    "        print(judgement)\n",
    "        results.append({\n",
    "            \"input\": row[\"input\"],\n",
    "            \"summary\": row[\"finetuned_summary\"],\n",
    "            \"llm_judgement\": judgement\n",
    "        })\n",
    "        time.sleep(1.1)  # Increase sleep to avoid rate limits\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        results.append({\n",
    "            \"input\": row[\"input\"],\n",
    "            \"summary\": row[\"finetuned_summary\"],\n",
    "            \"llm_judgement\": str(e)\n",
    "        })\n",
    "\n",
    "pd.DataFrame(results).to_csv(\"llm_judge_results_deepseek.csv\", index=False)\n",
    "print(\"Saved results to llm_judge_results_deepseek.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77a8fed-a0c2-4070-9fd3-940970b760e3",
   "metadata": {},
   "source": [
    "# Part 5: App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08c8cf7f-eeae-45ca-b73d-b0835014cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import PyPDF2\n",
    "import openai\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df0320d1-d8d4-4162-b3d9-926077569fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Setup ---\n",
    "finetuned_model_path = \"./lora-llama3-3b-arxiv/final\"\n",
    "base_model_path = \"./Llama-3.2-3B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14f428d8-ed12-497f-b5dc-3992622112bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Summarization Function ---\n",
    "def summarize(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=\"max_length\")\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=128,\n",
    "            num_beams=4,\n",
    "            do_sample=False\n",
    "        )\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbc7195a-59cc-4582-90cf-07c04282544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LLM-as-a-Judge Function ---\n",
    "def llm_judge(input_text, summary, api_key, judge_model=\"deepseek-ai/DeepSeek-V3\"):\n",
    "    client = openai.OpenAI(\n",
    "        api_key=api_key,\n",
    "        base_url=\"https://api.together.xyz/v1\"\n",
    "    )\n",
    "    prompt = f\"\"\"\n",
    "Given the following input and the summary produced, evaluate the summary on:\n",
    "1. Fluency (Is the summary readable and grammatically correct?)\n",
    "2. Factuality (Are the statements in the summary correct, and do they reflect the source?)\n",
    "3. Coverage (Does the summary include the main problem, method, and key findings?)\n",
    "\n",
    "Use a score from 1 (poor) to 5 (excellent) for each. Provide a short justification for each score.\n",
    "\n",
    "Input: {input_text[:4000]}\n",
    "Generated Summary: {summary}\n",
    "\n",
    "Respond in this format:\n",
    "Fluency: [score] - [justification]\n",
    "Factuality: [score] - [justification]\n",
    "Coverage: [score] - [justification]\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=judge_model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=256,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6ebb884-b951-4dc3-9fc8-f255c6fb62a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PDF/Text Extractor ---\n",
    "def extract_text(file):\n",
    "    if file.name.endswith(\".pdf\"):\n",
    "        pdf = PyPDF2.PdfReader(file)\n",
    "        text = \"\\n\".join(page.extract_text() for page in pdf.pages if page.extract_text())\n",
    "    else:\n",
    "        text = file.read().decode(\"utf-8\")\n",
    "    return text\n",
    "\n",
    "# --- File Processing ---\n",
    "def process_file(file, api_key):\n",
    "    text = extract_text(file)\n",
    "    finetuned_summary = summarize(text, finetuned_model, finetuned_tokenizer)\n",
    "    base_summary = summarize(text, base_model, base_tokenizer)\n",
    "    return text[:1000], finetuned_summary, base_summary, api_key\n",
    "\n",
    "# --- Metric Plot ---\n",
    "def generate_metric_plot():\n",
    "    metrics = [\"ROUGE-1\", \"ROUGE-L\", \"BLEU\", \"BERTScore\"]\n",
    "    fine_tuned_scores = [0.273244, 0.140273, 0.025094, 0.830307]\n",
    "    base_scores = [0.274378, 0.141729, 0.026383, 0.830307]\n",
    "\n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.bar(x - width/2, fine_tuned_scores, width, label=\"Fine-Tuned\")\n",
    "    ax.bar(x + width/2, base_scores, width, label=\"Base\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.set_title(\"Evaluation Metrics Comparison\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metrics)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d5b8dc9-7bbe-4583-921c-368dfdf915bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LLM-as-a-Judge Plot ---\n",
    "def parse_judge_scores(judge_text):\n",
    "    pattern = r\"(Fluency|Factuality|Coverage):\\s*(\\d)\"\n",
    "    scores = dict(re.findall(pattern, judge_text))\n",
    "    return [int(scores.get(key, 0)) for key in [\"Fluency\", \"Factuality\", \"Coverage\"]]\n",
    "\n",
    "def plot_judge_scores(finetuned_text, base_text):\n",
    "    categories = [\"Fluency\", \"Factuality\", \"Coverage\"]\n",
    "    fine_scores = parse_judge_scores(finetuned_text)\n",
    "    base_scores = parse_judge_scores(base_text)\n",
    "\n",
    "    x = np.arange(len(categories))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.bar(x - width/2, fine_scores, width, label=\"Fine-Tuned\")\n",
    "    ax.bar(x + width/2, base_scores, width, label=\"Base\")\n",
    "    ax.set_ylabel(\"Score (1–5)\")\n",
    "    ax.set_title(\"LLM-as-a-Judge Evaluation\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(categories)\n",
    "    ax.set_ylim(0, 5)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a00a758d-d777-4c53-ab51-56be3e2fce10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# --- Gradio Interface ---\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Research Paper Summarizer & LLM-as-a-Judge\")\n",
    "\n",
    "    file = gr.File(label=\"Upload PDF or TXT\")\n",
    "    api_key = gr.Textbox(label=\"Together.ai API Key\", type=\"password\")\n",
    "\n",
    "    summarize_btn = gr.Button(\"Summarize\")\n",
    "\n",
    "    input_text = gr.Textbox(label=\"Original Text (first 1000 chars)\", interactive=False)\n",
    "    finetuned_summary = gr.Textbox(label=\"Fine-tuned Model Summary\", interactive=False)\n",
    "    base_summary = gr.Textbox(label=\"Base Model Summary\", interactive=False)\n",
    "\n",
    "    judge_finetuned_btn = gr.Button(\"Judge Fine-tuned Summary\")\n",
    "    judge_base_btn = gr.Button(\"Judge Base Summary\")\n",
    "    judge_finetuned_output = gr.Textbox(label=\"LLM-as-a-Judge (Fine-tuned)\", interactive=False)\n",
    "    judge_base_output = gr.Textbox(label=\"LLM-as-a-Judge (Base)\", interactive=False)\n",
    "\n",
    "    plot_metrics_btn = gr.Button(\"Show Evaluation Metrics Plot\")\n",
    "    metric_plot = gr.Plot(label=\"Evaluation Metric Comparison\")\n",
    "\n",
    "    plot_judge_btn = gr.Button(\"Show LLM-as-a-Judge Plot\")\n",
    "    judge_plot = gr.Plot(label=\"LLM-as-a-Judge Score Comparison\")\n",
    "\n",
    "    summarize_btn.click(\n",
    "        process_file,\n",
    "        inputs=[file, api_key],\n",
    "        outputs=[input_text, finetuned_summary, base_summary, api_key]\n",
    "    )\n",
    "\n",
    "    judge_finetuned_btn.click(\n",
    "        llm_judge,\n",
    "        inputs=[input_text, finetuned_summary, api_key],\n",
    "        outputs=judge_finetuned_output\n",
    "    )\n",
    "\n",
    "    judge_base_btn.click(\n",
    "        llm_judge,\n",
    "        inputs=[input_text, base_summary, api_key],\n",
    "        outputs=judge_base_output\n",
    "    )\n",
    "\n",
    "    plot_metrics_btn.click(\n",
    "        generate_metric_plot,\n",
    "        inputs=[],\n",
    "        outputs=metric_plot\n",
    "    )\n",
    "\n",
    "    plot_judge_btn.click(\n",
    "        plot_judge_scores,\n",
    "        inputs=[judge_finetuned_output, judge_base_output],\n",
    "        outputs=judge_plot\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61c2f5c-d02a-4151-8a0e-4b78ff90eab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter-gpu)",
   "language": "python",
   "name": "jupyter-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
